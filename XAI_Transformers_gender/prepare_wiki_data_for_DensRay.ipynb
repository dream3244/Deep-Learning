{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(current_dir)\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import tqdm \n",
    "\n",
    "from bias_bench.dataset import load_sentence_debias_data\n",
    "from bias_bench.debias import DensRay\n",
    "\n",
    "from bias_bench.model import models\n",
    "from bias_bench.util import generate_experiment_id\n",
    "import json\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test & config\n",
    "* **tokenizer**:\n",
    "**tokenizer.encode_plus** return a dict \\\n",
    "'special_tokens_mask'\\\n",
    "'input_ids'\\\n",
    "'token_type_ids'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "config = 'base' #'base'\n",
    "nlayer = 12 if config == 'base' else 24\n",
    "nsamples = 50000\n",
    "\n",
    "model = transformers.BertForMaskedLM.from_pretrained('bert-'+config+'-uncased', output_hidden_states=True).to(device)\n",
    "\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('bert-'+config+'-uncased')\n",
    "\n",
    "#tokenizer = transformers.BertTokenizer.from_pretrained('bert-'+config+'-uncased')\n",
    "# turn on eval mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'special_tokens_mask': [1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " 'input_ids': tensor([[ 101, 1045, 2657, 2008, 2017, 2031, 2042, 2182, 1012,  102]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I heard that you have been here.\"\n",
    "tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=512\n",
    "                      , return_tensors='pt')#[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1045, 2657, 2008, 2017, 2031, 2042, 2182, 1012, 102]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=512\n",
    "                      , return_tensors='pt')[\"input_ids\"]\n",
    "ids[0].tolist()#.index(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1045, 2657, 2008, 2017, 2031, 2042, 2182, 1012]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(sentence,\n",
    "            #return_tensors=\"pt\",\n",
    "            #truncation=True,\n",
    "            #padding=\"max_length\",\n",
    "            #max_length=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collecting data and gender words\n",
    "* **prepare attribute words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonpath = \"./data/bias_attribute_words.json\"\n",
    "with open(jsonpath, \"r\") as f:\n",
    "    attribute_words = json.load(f)[\"gender\"]\n",
    "attribute_word = []  \n",
    "for i, (female_word, male_word) in enumerate(attribute_words):\n",
    "    # just want words with one token!\n",
    "    if (female_word in tokenizer.vocab.keys()) and (male_word in tokenizer.vocab.keys()):\n",
    "        attribute_word.append([female_word,male_word])\n",
    "        \n",
    "len(attribute_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* check whether they can be encoded in 1 token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (female_word, male_word) in enumerate(attribute_word):\n",
    "    if(len(tokenizer.encode(female_word))>1):\n",
    "        print(female_word)\n",
    "    if(len(tokenizer.encode(male_word))>1):\n",
    "        print(male_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **collect wiki-text(CDA)**\n",
    "* dataset from: https://drive.google.com/file/d/1nGcRFOBep_M7HjvC_qM-9JFee_rWQRQO/view\n",
    "*  path : \"./data/text/wikipedia-2.5.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1095911"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wikipath = \"./data/text/wikipedia-2.5.txt\"\n",
    "# from wiki-2.5.txt\n",
    "data_all = load_sentence_debias_data(\n",
    "        persistent_dir=\"./\", bias_type=\"gender\", lang_debias=\"en\"\n",
    "    ) #female_example\n",
    "len(data_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'female_example': 'he has also been a prominent member of the suicide squad since its second iteration in the late 1990s.',\n",
       " 'male_example': 'she has also been a prominent member of the suicide squad since its second iteration in the late 1990s.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_examples():\n",
    "    \n",
    "    examples = []\n",
    "    labels = []\n",
    "    \n",
    "    for sentence_dict in tqdm(data_all, desc=f\"Collecting examples\", leave=False):\n",
    "        female_sent = sentence_dict['female_example']\n",
    "        male_sent = sentence_dict['male_example']\n",
    "        female_sent = female_sent.lower()\n",
    "        male_sent = male_sent.lower()\n",
    "        female_sent = female_sent.strip()\n",
    "        male_sent = male_sent.strip()\n",
    "        \n",
    "        female_words = female_sent.split(\" \")\n",
    "        male_words = male_sent.split(\" \")\n",
    "        \n",
    "        female_ids = tokenizer.encode_plus(female_sent, add_special_tokens=True, max_length=512\n",
    "                      , return_tensors='pt')[\"input_ids\"]\n",
    "        male_ids = tokenizer.encode_plus(male_sent, add_special_tokens=True, max_length=512\n",
    "                      , return_tensors='pt')[\"input_ids\"]\n",
    "        # NOTE! with special tokens!!\n",
    "        \n",
    "        for i, (female_word, male_word) in enumerate(attribute_word):\n",
    "            if female_word in female_words and male_word in male_words:\n",
    "                f_id = tokenizer.encode(female_word)\n",
    "                examples.append(female_ids)\n",
    "                # loc !=0 cls\n",
    "                loc = female_ids[0].tolist().index(f_id[0])\n",
    "                labels.append(-loc)\n",
    "\n",
    "                m_id = tokenizer.encode(male_word)\n",
    "                examples.append(male_ids)\n",
    "                loc = male_ids[0].tolist().index(m_id[0])\n",
    "                labels.append(loc)\n",
    "\n",
    "    return examples,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting examples:   0%|          | 0/1095911 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting examples:  61%|██████    | 669314/1095911 [13:11<06:50, 1038.97it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "Collecting examples:  91%|█████████ | 996407/1095911 [19:37<02:14, 740.21it/s] Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "Collecting examples:  98%|█████████▊| 1075666/1095911 [21:08<00:21, 947.53it/s] Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 512). Running this sequence through the model will result in indexing errors\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "examples,labels = load_examples()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# write into file for training \n",
    "with open(\"./data/text/wiki-all-250k.txt\", 'wb') as file:\n",
    "    pickle.dump((examples,labels), file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* test: read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2272422\n",
      "tensor([[  101,  2002,  2038,  2036,  2042,  1037,  4069,  2266,  1997,  1996,\n",
      "          5920,  4686,  2144,  2049,  2117, 27758,  1999,  1996,  2397,  4134,\n",
      "          1012,   102]])\n",
      "2272422\n"
     ]
    }
   ],
   "source": [
    "# read file \n",
    "with open(\"./data/text/wiki-all-250k.txt\", 'rb') as file:\n",
    "    example, label = pickle.load(file)\n",
    "print(len(example))\n",
    "print(example[0])\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2002, 2038]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[0][0][:3].unsqueeze(dim=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
