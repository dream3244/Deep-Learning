{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iopC7uMt37z-",
        "outputId": "2f6b755e-0ad1-48bc-a642-00bf755186ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec 22 18:56:42 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu3gKP0V370B",
        "outputId": "62ccfbe0-40fb-43fc-8619-c474a34caa87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/MyDrive/MTminiproject/densray-debiasing-publish\n",
            " conceptor_bert.py\t\t      professions.json\n",
            " data\t\t\t\t      __pycache__\n",
            " densray_bert_1.py\t\t      questions-words.txt\n",
            " densray_bert_a.py\t\t      README.md\n",
            " DensRay_BERT-base_Wikitext.ipynb     result\n",
            " DensRay_BERT_Glue.ipynb\t      run_glue_conceptor.py\n",
            " densray_bert.py\t\t      run_glue_densray.py\n",
            " DensRay_BERT_TEST.ipynb\t      run_glue_hard.py\n",
            " DensRay_Bias_Measurement.ipynb       run_glue.py\n",
            " DensRay_heatmap.ipynb\t\t      run_language_modeling_conceptor.py\n",
            " DensRay_Multilingual_BERT_CH.ipynb   run_language_modeling_densray.py\n",
            " DRBERT_WEAT.ipynb\t\t      run_language_modeling_hard.py\n",
            " DR_bias_layers_calculate.ipynb      'Training for DR subspace.ipynb'\n",
            " hard_bert.py\t\t\t      Train.ipynb\n",
            " newresult\t\t\t      wiki-250k.txt\n",
            " professions_ch.txt\t\t      wiki-all-250k.txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/MyDrive/MTminiproject/densray-debiasing-publish/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "h0sArdzZ370E"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import argparse\n",
        "import glob\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm as tqdm\n",
        "from scipy.special import softmax\n",
        "import scipy.stats as stats\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukVsCMX1370G"
      },
      "source": [
        "## config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c91dc4321b394f4d95ecda29b0394a01",
            "5093c59edce24ff788270b14fca0980d",
            "f262b473bfdc46a99db7eed418efd951",
            "27a1fe9f0bea444f8b66aa9f8c546a95",
            "07a754db1429439aa2045afa47b53442",
            "8e58a6f428a84c59af4af9e395e08fd5",
            "984708f5b5fe46389ef3dcf84ff2d728",
            "f04d6432db274836b9bd8cb274f5f6f2",
            "391e93da1d164ea7a9bd6fa68056d0a8",
            "7a262832ada24a31b89503afb4cecf21",
            "2416a47d596c4c87b142feb8b13b011c",
            "8852df70a1e44795915522025ba23892",
            "e5cd1924a30d4d61b887989346a175bf",
            "9bc8edac6b054082b1735f55de306319",
            "dc16f7cb927b40b7afb3cde01a2d3995",
            "3f94babc44ce4087bc9fddbebedcf17c",
            "4655b2acfa0846c988f410aad779244c",
            "2191a38c63aa45c2823ac548b9f03f26",
            "7d254e59251f4d43ac220b333a7002bb",
            "944d0c0a57de49a68c6d1bbe42b416a5",
            "eff1abe001524a598f30667490c81774",
            "ee511efd47684244806e17a38add6c97",
            "4329830733bb430697062ea3884e67ff",
            "f69efb327b1745f480cd22b8f455fc91",
            "cea1a08d60114a5dbe1804262c44a781",
            "e1400398d3c24e29856c53d52a1de974",
            "a4a222d08ee3433e8260d65b9c03e59f",
            "15b7d28f38ef4682bc6c5515ed234c31",
            "0d6ed38204384154b69de59d7f1dc1d4",
            "828f2f9c7442447fa449d6b18c5424cd",
            "15b6e474703c47e0891ebdb0d643bb8e",
            "e85d846df38d4be385e6882d28f774bc",
            "383e1ecfe88642a7983822764ac25d28",
            "5485e05ad26d461d9b666ce5527ac067",
            "a13367f35dc84f84a3d3285a88ce9ce1",
            "c20d0f7bd6844413825adf9d55323f9b",
            "813f14639baf4263a0c7ad33d3b9c6d0",
            "deabb35d3d4b4939b6130641b3d0ce16",
            "15151a03869e479abcaf54f65e50028c",
            "18ae677439dc41d8932167b6a249a917",
            "9e8de59926e2458b8f585aa3f3630366",
            "24bbd3af20a94bc28af3d6330e21fc25",
            "e3cde637ecfc4f3baeb63737300d9866",
            "2d04a8b05fc44858b83355025cb3f15a",
            "2af3415d4055439a81056171366ccc19",
            "368ba8ef5f864e0c9bc9a2b79c4275aa",
            "765a9ed9044d4a5398924a45e46ed0d6",
            "d3fcbf04b57c4880a9046c5b9272248f",
            "8aef96e1b08641698c2af201d237283d",
            "9f21c020ee9544b5bf81228e237d2b3d",
            "86974ccdf4dd478c82e2a428554e72fa",
            "c720df2a03634c1a85961b7ff168a837",
            "fa77eff8475f4c1bbc9404660e6aa4bb",
            "c64aff0d7e5044a487da7df3e38fa89f",
            "c3bf0b315304434bb7b52be6a9f35c3a"
          ]
        },
        "id": "xPywQSr8370I",
        "outputId": "e090a7d6-1f95-4d6c-e9d1-4c3451623bcf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c91dc4321b394f4d95ecda29b0394a01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8852df70a1e44795915522025ba23892"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4329830733bb430697062ea3884e67ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5485e05ad26d461d9b666ce5527ac067"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2af3415d4055439a81056171366ccc19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (transform_act_fn): GELUActivation()\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import torch\n",
        "import transformers\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "config = 'base'\n",
        "nlayer = 12 if config == 'base' else 24\n",
        "nsamples = 50000 if config == 'base' else 100000\n",
        "\n",
        "model = transformers.BertForMaskedLM.from_pretrained('bert-'+config+'-uncased', output_hidden_states=True).to(device)\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained('bert-'+config+'-uncased')\n",
        "# turn on eval mode\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# template--OCCTMP\n",
        "**NOTE**\\\n",
        "**need to add extra attention_mask!!**\n",
        "\n",
        "## outline\n",
        "* [MASK] is the *profession* in this area.\n",
        "* calculate [MASK] == he/she probability\n",
        "* consider it as a classification problem, \\\n",
        "calculate the raw attention weight, CAT score and AttCAT scores\n",
        "* visualize it in a heatmap later\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dKLYbVMxg2fI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## template_log"
      ],
      "metadata": {
        "id": "JdFHQYV-mdw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Template_log:\n",
        "    def __init__(self, path='/content/drive/My Drive/professions.json'):\n",
        "        with open(path,'r',encoding='utf8') as f:\n",
        "            titles = re.sub('[^a-z_]',' ',f.read()).split()\n",
        "        # mask is a mask\n",
        "        self.lines_prior = [re.sub('_',' ',tokenizer.mask_token+' is the '+tokenizer.mask_token+' in this area.')]\n",
        "        encoding = tokenizer.batch_encode_plus(self.lines_prior, add_special_tokens=True, max_length=128)\n",
        "        self.examples_prior = encoding[\"input_ids\"]\n",
        "        self.attention_mask = encoding[\"attention_mask\"]\n",
        "        self.getbaseline()\n",
        "\n",
        "    def getbaseline(self):\n",
        "        # return probability of he/she in first token\n",
        "        def get_probs(example=self.examples_prior,mask = self.attention_mask):\n",
        "          baseline = []\n",
        "          for i in range(len(self.examples_prior)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples_prior[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            output = model(vec,attention_mask=mask)\n",
        "            #output = model(vec)\n",
        "            mask_hidden_state = output[0].squeeze(0)[1]\n",
        "            softmax = torch.nn.Softmax(dim=0)\n",
        "            torch.set_grad_enabled(False)\n",
        "            probs = softmax(mask_hidden_state)\n",
        "            # get probability of token 'he'\n",
        "            he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "            #print('he probability', probs[he_id].item())\n",
        "            # get probability of token 'she'\n",
        "            she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "            #print('she probability', probs[she_id].item())\n",
        "            baseline.append([probs[he_id].item(), probs[she_id].item()])\n",
        "          return baseline\n",
        "        self.baseline_prior = get_probs(self.examples_prior,self.attention_mask)\n",
        "\n",
        "template_log = Template_log('./professions.json')"
      ],
      "metadata": {
        "id": "zpsLj4YCIR3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_log.baseline_prior"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vB4N-kcBmFvA",
        "outputId": "68fa358a-7d5e-4f3f-ce58-5496e586a4ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.02757858671247959, 0.028956476598978043]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./newresult/OCCTMP_baseline.txt\", \"wb\") as handle:\n",
        "  pickle.dump(template_log.baseline_prior, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "-V1WV5GLomwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## template"
      ],
      "metadata": {
        "id": "guT7nInVmh06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class Template:\n",
        "    def __init__(self, path='/content/drive/My Drive/professions.json'):\n",
        "        with open(path,'r',encoding='utf8') as f:\n",
        "            titles = re.sub('[^a-z_]',' ',f.read()).split()\n",
        "        #\n",
        "        self.lines = [re.sub('_',' ',tokenizer.mask_token+' is the '+i+' in this area.') for i in titles]\n",
        "        encoding = tokenizer.batch_encode_plus(self.lines, add_special_tokens=True, max_length=128)\n",
        "        self.examples = encoding[\"input_ids\"]\n",
        "        self.attention_mask = encoding[\"attention_mask\"]\n",
        "        self.getbaseline()\n",
        "        #self.get_bias_score_per_layer()\n",
        "\n",
        "    def getbaseline(self):\n",
        "        # get new prob of he/she\n",
        "        self.baseline = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            output = model(vec,attention_mask=mask)\n",
        "            #output = model(vec)\n",
        "            mask_hidden_state = output[0].squeeze(0)[1]\n",
        "            softmax = torch.nn.Softmax(dim=0)\n",
        "            torch.set_grad_enabled(False)\n",
        "            probs = softmax(mask_hidden_state)\n",
        "            # get probability of token 'he'\n",
        "            he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "            #print('he probability', probs[he_id].item())\n",
        "            # get probability of token 'she'\n",
        "            she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "            #print('she probability', probs[she_id].item())\n",
        "            self.baseline.append([probs[he_id].item(), probs[she_id].item()])\n",
        "\n",
        "    def get_bias_score_per_layer(self):\n",
        "        self.bias_score_per_layer = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            bias_mat = np.zeros((nlayer,len(self.examples[i])-2))\n",
        "            # (num_token, 768) @ (768,768)\n",
        "            for layer in range(nlayer):\n",
        "                # get embedding of each layer\n",
        "                output = model(vec,attention_mask=mask)[1][layer+1][0][1:-1]\n",
        "                #output = model(vec)[1][layer+1][0][1:-1]\n",
        "                eigvec = torch.load('./result/DR/eigvecs_'+config+'_wiki_'+str(nsamples)+'_'+str(layer)+'.pt').to(device)\n",
        "\n",
        "                bias = torch.mm(output, eigvec)[:, 0]\n",
        "                bias_mat[layer] = np.array(bias.tolist())\n",
        "            self.bias_score_per_layer.append({\"sentence\":self.lines[i],\"tokens\":self.examples[i],\"mat\":bias_mat})\n",
        "        return self.bias_score_per_layer\n",
        "\n",
        "template = Template('./professions.json')\n"
      ],
      "metadata": {
        "id": "_AjuWEfxjIy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(template.baseline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzetFLMgooav",
        "outputId": "abae5769-21fa-4d0b-f571-bb4e6f1ec0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11095110332753393"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ipUdlwDIqiNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./newresult/OCCTMP_prob.txt\", \"wb\") as handle:\n",
        "  pickle.dump(template.baseline, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "vTENRUJpgrEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ATTCAT calculation"
      ],
      "metadata": {
        "id": "h4cjgz6Sms3_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNASZW9m370K"
      },
      "outputs": [],
      "source": [
        "text_batch = [i for i in template.lines]\n",
        "\n",
        "all_map = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "\n",
        "\n",
        "for id in range(len(template.examples)):\n",
        "\n",
        "  encoding  = tokenizer.encode_plus(text_batch[id], add_special_tokens=True, max_length=128,return_tensors=\"pt\")\n",
        "  input_ids = encoding['input_ids'].to(device)\n",
        "  attention_mask = encoding['attention_mask'].to(device)\n",
        "  attention_mask[0][0] = 0\n",
        "  attention_mask[0][-1] = 0\n",
        "  tokens = tokenizer.convert_ids_to_tokens(input_ids.flatten())\n",
        "  result = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True,output_attentions=True)\n",
        "  hs = result[1]\n",
        "  mask_hidden_state = result[0].squeeze(0)[1]\n",
        "\n",
        "  softmax = torch.nn.Softmax(dim=0)\n",
        "  torch.set_grad_enabled(True)\n",
        "\n",
        "  probs = softmax(mask_hidden_state)\n",
        "\n",
        "  he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "  she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "  # 1 he 0 she\n",
        "  index = np.argmax(probs.tolist())#he_id #if mask_hidden_state[he_id].item()>mask_hidden_state[she_id].item() else she_id\n",
        "\n",
        "  # blk_id = layer id\n",
        "  kwargs = {\"alpha\": 1}\n",
        "\n",
        "  # turn the binary result[0] into real category (with max prob) tensor one_hot\n",
        "  one_hot = np.zeros((1, mask_hidden_state.size()[-1]), dtype=np.float32) # array([[0., 0.]], dtype=float32)\n",
        "  one_hot[0, index] = 1 # array([[1., 0.]], dtype=float32)\n",
        "  one_hot_vector = one_hot\n",
        "  one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
        "  one_hot = torch.sum(one_hot.to(device) * mask_hidden_state) #tensor(1.9705, device='cuda:0', grad_fn=<SumBackward0>)\n",
        "  for blk_id in range(nlayer):\n",
        "    hs[blk_id].retain_grad()\n",
        "\n",
        "  model.zero_grad()\n",
        "  one_hot.backward(retain_graph=True)\n",
        "\n",
        "\n",
        "  mask_id=1\n",
        "  AttCAT = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "  raws = []\n",
        "  CAT_h = []\n",
        "  CAT=[]\n",
        "  for blk_id in range(nlayer):\n",
        "      hs_grads = hs[blk_id].grad\n",
        "      # # [batchsize, head, num_token, num_token].squeeze -- [head, num_token, num_token]\n",
        "      raw = result[2][blk_id].squeeze(0) # shape torch.Size([12, 13, 13])\n",
        "      avghead = raw.mean(dim=0)\n",
        "      att = avghead[mask_id] # torch.Size([13]) Q_mask_id\n",
        "      avgtoken = raw[:,mask_id,:].mean(dim=-1)#.mean(dim=-1)\n",
        "\n",
        "      # torch.Size([1, 13, 768])\n",
        "      # hidden states average pooling\n",
        "      cat = (hs_grads * hs[blk_id]).sum(dim=-1).squeeze(0)\n",
        "      CAT.append(cat.cpu().detach().numpy())\n",
        "      cat = cat * att # hardmard product\n",
        "\n",
        "      #avgtoken = avgtoken * cat\n",
        "\n",
        "      cat = cat.cpu().detach().numpy()\n",
        "      avgtoken = avgtoken.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "      AttCAT.append(cat) # torch.Size([13])\n",
        "      CAT_h.append(avgtoken)\n",
        "      raws.append(att.cpu().detach().numpy())\n",
        "\n",
        "  AttCAT = np.array(AttCAT)[:,1:-1]\n",
        "\n",
        "  raws = np.array(raws)[:,1:-1]\n",
        "\n",
        "  CAT_h = np.array(CAT_h) # 12*12\n",
        "  CAT = np.array(CAT)[:,1:-1]\n",
        "  all_map.append({\"AttCAT\":AttCAT\n",
        "                  ,\"raws\":raws\n",
        "                  ,\"CAT_h\":CAT_h\n",
        "                  ,\"CAT\":CAT\n",
        "                  ,\"lines\":text_batch[id]\n",
        "                  ,\"tokens\":tokens\n",
        "                  ,\"mask\":attention_mask})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./newresult/OCCTMP_mask_AttCAT_origin.txt\", \"wb\") as handle:\n",
        "  pickle.dump(all_map, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "I6d5sZ0jQ5nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./newresult/OCCTMP_mask_AttCAT.txt\", \"rb\") as file:\n",
        "  Att_cat = pickle.load(file)"
      ],
      "metadata": {
        "id": "IuuJ-qpg-4FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* view it as a binary classification problem and test how much impact score shows that the gender depends on the occupation"
      ],
      "metadata": {
        "id": "WwWL9ItxEr_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ismax = np.zeros(len(Att_cat))\n",
        "ratio = np.zeros(len(Att_cat))# the percentage for the word of the whole sentence\n",
        "for i in range(len(Att_cat)):\n",
        "  score = Att_cat[i][\"AttCAT\"].sum(axis=0)[1:].tolist() # impact score without mask\n",
        "  abs_s = [abs(k) for k in score]\n",
        "  ratio[i] = abs_s[2]/sum(abs_s)\n",
        "  ismax[i] = 1 if np.argmax(abs_s)==2 else 0\n",
        "\n",
        "print(\"mean ratio of occupation word:\",ratio.mean())\n",
        "ismax.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELy4e3goBGK0",
        "outputId": "9d12ad78-69db-43a1-925a-cfd7c1d8cfd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean ratio of occupation word: 0.1970570462193119\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75.0"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# template-ADJTMP\n",
        "* mask is a mask person\n",
        "* adj range: intelligence vs appearance"
      ],
      "metadata": {
        "id": "mUMnLn4Jsg0p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### adj_template log\n"
      ],
      "metadata": {
        "id": "VU4skfgzuP-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ADJTemplate_log:\n",
        "    def __init__(self):\n",
        "        # mask is a mask person\n",
        "        self.lines_prior = [re.sub('_',' ',tokenizer.mask_token+' is a '+tokenizer.mask_token+' person.')]\n",
        "        encoding = tokenizer.batch_encode_plus(self.lines_prior, add_special_tokens=True, max_length=128)\n",
        "        self.examples_prior = encoding[\"input_ids\"]\n",
        "        self.attention_mask = encoding[\"attention_mask\"]\n",
        "        self.getbaseline()\n",
        "\n",
        "    def getbaseline(self):\n",
        "        # return probability of he/she in first token\n",
        "        def get_probs(example=self.examples_prior,mask = self.attention_mask):\n",
        "          baseline = []\n",
        "          for i in range(len(self.examples_prior)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples_prior[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            output = model(vec,attention_mask=mask)\n",
        "            #output = model(vec)\n",
        "            mask_hidden_state = output[0].squeeze(0)[1]\n",
        "            softmax = torch.nn.Softmax(dim=0)\n",
        "            torch.set_grad_enabled(False)\n",
        "            probs = softmax(mask_hidden_state)\n",
        "            # get probability of token 'he'\n",
        "            he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "            #print('he probability', probs[he_id].item())\n",
        "            # get probability of token 'she'\n",
        "            she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "            #print('she probability', probs[she_id].item())\n",
        "            baseline.append([probs[he_id].item(), probs[she_id].item()])\n",
        "          return baseline\n",
        "        self.baseline_prior = get_probs(self.examples_prior,self.attention_mask)\n",
        "\n",
        "adj_template_log = ADJTemplate_log()"
      ],
      "metadata": {
        "id": "uuStc1A7snU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01bf9fa2-0d07-4fa7-bd73-e9248205cd1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adj_template_log.baseline_prior"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7hcnfJYu7nF",
        "outputId": "0b54670c-6ac6-437b-f382-f6c037154a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.03779642656445503, 0.028690209612250328]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ADJTemplate_female & ADJTemplate_male\n",
        "* scope: intelligence & appearance"
      ],
      "metadata": {
        "id": "p_AwCjQX1gKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class ADJTemplate_female:\n",
        "    def __init__(self):\n",
        "        adj_m = \"precocious, resourceful, inquisitive, genius, inventive, astute, adaptable, reflective,discerning, intuitive, inquiring, judicious, analytical, apt, venerable, imaginative,shrewd, thoughtful, wise, smart, ingenious, clever, brilliant, logical, intelligent\".lower().replace(\" \", \"\").split(',')\n",
        "        adj_f = \"alluring, voluptuous, blushing, homely, plump, sensual, gorgeous, slim, bald,athletic, fashionable, stout, ugly, muscular, slender, feeble, handsome, healthy,attractive, fat, weak, thin, pretty, beautiful, strong\".lower().replace(\" \", \"\").split(',')\n",
        "        self.lines = [re.sub('_',' ',tokenizer.mask_token+' is a '+i+' person.') for i in adj_f]\n",
        "        encoding = tokenizer.batch_encode_plus(self.lines, add_special_tokens=True, max_length=128)\n",
        "        self.examples = encoding[\"input_ids\"]\n",
        "        self.attention_mask = encoding[\"attention_mask\"]\n",
        "        self.getbaseline()\n",
        "        self.get_bias_score_per_layer()\n",
        "\n",
        "    def getbaseline(self):\n",
        "        # get new prob of he/she\n",
        "        self.baseline = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            output = model(vec,attention_mask=mask)\n",
        "            #output = model(vec)\n",
        "            mask_hidden_state = output[0].squeeze(0)[1]\n",
        "            softmax = torch.nn.Softmax(dim=0)\n",
        "            torch.set_grad_enabled(False)\n",
        "            probs = softmax(mask_hidden_state)\n",
        "            # get probability of token 'he'\n",
        "            he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "            #print('he probability', probs[he_id].item())\n",
        "            # get probability of token 'she'\n",
        "            she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "            #print('she probability', probs[she_id].item())\n",
        "            self.baseline.append([probs[he_id].item(), probs[she_id].item()])\n",
        "\n",
        "    def get_bias_score_per_layer(self):\n",
        "        self.bias_score_per_layer = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            bias_mat = np.zeros((nlayer,len(self.examples[i])-2))\n",
        "            # (num_token, 768) @ (768,768)\n",
        "            for layer in range(nlayer):\n",
        "                # get embedding of each layer\n",
        "                output = model(vec,attention_mask=mask)[1][layer+1][0][1:-1]\n",
        "                #output = model(vec)[1][layer+1][0][1:-1]\n",
        "                eigvec = torch.load('./result/DR/eigvecs_'+config+'_wiki_'+str(nsamples)+'_'+str(layer)+'.pt').to(device)\n",
        "\n",
        "                bias = torch.mm(output, eigvec)[:, 0]\n",
        "                bias_mat[layer] = np.array(bias.tolist())\n",
        "            self.bias_score_per_layer.append({\"sentence\":self.lines[i],\"tokens\":self.examples[i],\"mat\":bias_mat})\n",
        "        return self.bias_score_per_layer\n",
        "\n",
        "template = ADJTemplate_female()\n"
      ],
      "metadata": {
        "id": "rDaLkX5KuPEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/ADJTMP_female_prob.txt\", \"wb\") as handle:\n",
        "  pickle.dump(template.baseline, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "0bQJJfEVyESS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/ADJTMP_female_DR.txt\", \"wb\") as handle:\n",
        "  pickle.dump(template.bias_score_per_layer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "bXVhPJqw9j7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_batch = [i for i in template.lines]\n",
        "\n",
        "all_map = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "\n",
        "\n",
        "for id in range(len(template.examples)):\n",
        "\n",
        "  encoding  = tokenizer.encode_plus(text_batch[id], add_special_tokens=True, max_length=128,return_tensors=\"pt\")\n",
        "  input_ids = encoding['input_ids'].to(device)\n",
        "  attention_mask = encoding['attention_mask'].to(device)\n",
        "  attention_mask[0][0] = 0\n",
        "  attention_mask[0][-1] = 0\n",
        "  tokens = tokenizer.convert_ids_to_tokens(input_ids.flatten())\n",
        "  result = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True,output_attentions=True)\n",
        "  hs = result[1]\n",
        "  mask_hidden_state = result[0].squeeze(0)[1]\n",
        "\n",
        "  softmax = torch.nn.Softmax(dim=0)\n",
        "  torch.set_grad_enabled(True)\n",
        "\n",
        "  probs = softmax(mask_hidden_state)\n",
        "\n",
        "  he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "  she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "  # 1 he 0 she\n",
        "  index = np.argmax(probs.tolist())#he_id #if mask_hidden_state[he_id].item()>mask_hidden_state[she_id].item() else she_id\n",
        "\n",
        "  # blk_id = layer id\n",
        "  kwargs = {\"alpha\": 1}\n",
        "\n",
        "  # turn the binary result[0] into real category (with max prob) tensor one_hot\n",
        "  one_hot = np.zeros((1, mask_hidden_state.size()[-1]), dtype=np.float32) # array([[0., 0.]], dtype=float32)\n",
        "  one_hot[0, index] = 1 # array([[1., 0.]], dtype=float32)\n",
        "  one_hot_vector = one_hot\n",
        "  one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
        "  one_hot = torch.sum(one_hot.to(device) * mask_hidden_state) #tensor(1.9705, device='cuda:0', grad_fn=<SumBackward0>)\n",
        "  for blk_id in range(nlayer):\n",
        "    hs[blk_id].retain_grad()\n",
        "\n",
        "  model.zero_grad()\n",
        "  one_hot.backward(retain_graph=True)\n",
        "\n",
        "\n",
        "  mask_id=1\n",
        "  AttCAT = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "  raws = []\n",
        "  CAT=[]\n",
        "  for blk_id in range(nlayer):\n",
        "      hs_grads = hs[blk_id].grad\n",
        "      # # [batchsize, head, num_token, num_token].squeeze -- [head, num_token, num_token]\n",
        "      raw = result[2][blk_id].squeeze(0) # shape torch.Size([12, 13, 13])\n",
        "      avghead = raw.mean(dim=0)\n",
        "      att = avghead[mask_id] # torch.Size([13]) Q_mask_id\n",
        "\n",
        "      # torch.Size([1, 13, 768])\n",
        "      # hidden states average pooling\n",
        "      cat = (hs_grads * hs[blk_id]).sum(dim=-1).squeeze(0)\n",
        "      CAT.append(cat.cpu().detach().numpy())\n",
        "      cat = cat * att # hardmard product\n",
        "\n",
        "      #avgtoken = avgtoken * cat\n",
        "\n",
        "      cat = cat.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "      AttCAT.append(cat) # torch.Size([13])\n",
        "      raws.append(att.cpu().detach().numpy())\n",
        "\n",
        "  AttCAT = np.array(AttCAT)[:,1:-1]\n",
        "\n",
        "  raws = np.array(raws)[:,1:-1]\n",
        "\n",
        "  CAT = np.array(CAT)[:,1:-1]\n",
        "  all_map.append({\"AttCAT\":AttCAT\n",
        "                  ,\"raws\":raws\n",
        "                  ,\"CAT\":CAT\n",
        "                  ,\"lines\":text_batch[id]\n",
        "                  ,\"tokens\":tokens})"
      ],
      "metadata": {
        "id": "4QPtTdpGyTOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/ADJTMP_female_AttCAT.txt\", \"wb\") as handle:\n",
        "  pickle.dump(all_map, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "WS6-f9KvyTX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Att_cat = all_map\n",
        "ismax = np.zeros(len(Att_cat))\n",
        "ratio = np.zeros(len(Att_cat))# the percentage for the word of the whole sentence\n",
        "for i in range(len(Att_cat)):\n",
        "  score = Att_cat[i][\"AttCAT\"].sum(axis=0)[1:].tolist() # impact score without mask\n",
        "  abs_s = [abs(k) for k in score]\n",
        "  ratio[i] = abs_s[2]/sum(abs_s)\n",
        "  ismax[i] = 1 if np.argmax(abs_s)==2 else 0\n",
        "\n",
        "print(\"mean ratio of occupation word:\",ratio.mean())\n",
        "print(\"number of samples:\", len(Att_cat))\n",
        "ismax.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUuxqqy5M4Gc",
        "outputId": "6f50b1b5-4d7c-4d5b-a367-72f478d52db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean ratio of occupation word: 0.1327479392660215\n",
            "number of samples: 25\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* for male adj list"
      ],
      "metadata": {
        "id": "A65AZF4HzOMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class ADJTemplate_male:\n",
        "    def __init__(self):\n",
        "        adj_m = \"precocious, resourceful, inquisitive, genius, inventive, astute, adaptable, reflective,discerning, intuitive, inquiring, judicious, analytical, apt, venerable, imaginative,shrewd, thoughtful, wise, smart, ingenious, clever, brilliant, logical, intelligent\".lower().replace(\" \", \"\").split(',')\n",
        "        adj_f = \"alluring, voluptuous, blushing, homely, plump, sensual, gorgeous, slim, bald,athletic, fashionable, stout, ugly, muscular, slender, feeble, handsome, healthy,attractive, fat, weak, thin, pretty, beautiful, strong\".lower().replace(\" \", \"\").split(',')\n",
        "        self.lines = [re.sub('_',' ',tokenizer.mask_token+' is a '+i+' person.') for i in adj_m]\n",
        "        encoding = tokenizer.batch_encode_plus(self.lines, add_special_tokens=True, max_length=128)\n",
        "        self.examples = encoding[\"input_ids\"]\n",
        "        self.attention_mask = encoding[\"attention_mask\"]\n",
        "        self.getbaseline()\n",
        "        self.get_bias_score_per_layer()\n",
        "\n",
        "    def getbaseline(self):\n",
        "        # get new prob of he/she\n",
        "        self.baseline = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            output = model(vec,attention_mask=mask)\n",
        "            #output = model(vec)\n",
        "            mask_hidden_state = output[0].squeeze(0)[1]\n",
        "            softmax = torch.nn.Softmax(dim=0)\n",
        "            torch.set_grad_enabled(False)\n",
        "            probs = softmax(mask_hidden_state)\n",
        "            # get probability of token 'he'\n",
        "            he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "            #print('he probability', probs[he_id].item())\n",
        "            # get probability of token 'she'\n",
        "            she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "            #print('she probability', probs[she_id].item())\n",
        "            self.baseline.append([probs[he_id].item(), probs[she_id].item()])\n",
        "\n",
        "    def get_bias_score_per_layer(self):\n",
        "        self.bias_score_per_layer = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            bias_mat = np.zeros((nlayer,len(self.examples[i])-2))\n",
        "            # (num_token, 768) @ (768,768)\n",
        "            for layer in range(nlayer):\n",
        "                # get embedding of each layer\n",
        "                output = model(vec,attention_mask=mask)[1][layer+1][0][1:-1]\n",
        "                #output = model(vec)[1][layer+1][0][1:-1]\n",
        "                eigvec = torch.load('./result/DR/eigvecs_'+config+'_wiki_'+str(nsamples)+'_'+str(layer)+'.pt').to(device)\n",
        "\n",
        "                bias = torch.mm(output, eigvec)[:, 0]\n",
        "                bias_mat[layer] = np.array(bias.tolist())\n",
        "            self.bias_score_per_layer.append({\"sentence\":self.lines[i],\"tokens\":self.examples[i],\"mat\":bias_mat})\n",
        "        return self.bias_score_per_layer\n",
        "\n",
        "template = ADJTemplate_male()\n"
      ],
      "metadata": {
        "id": "zcnc4hp_zMvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/ADJTMP_male_prob.txt\", \"wb\") as handle:\n",
        "  pickle.dump(template.baseline, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "cTYT9byGzM5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/ADJTMP_male_DR.txt\", \"wb\") as handle:\n",
        "  pickle.dump(template.bias_score_per_layer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "8oARPNbO9pgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_batch = [i for i in template.lines]\n",
        "\n",
        "all_map = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "\n",
        "\n",
        "for id in range(len(template.examples)):\n",
        "\n",
        "  encoding  = tokenizer.encode_plus(text_batch[id], add_special_tokens=True, max_length=128,return_tensors=\"pt\")\n",
        "  input_ids = encoding['input_ids'].to(device)\n",
        "  attention_mask = encoding['attention_mask'].to(device)\n",
        "  attention_mask[0][0] = 0\n",
        "  attention_mask[0][-1] = 0\n",
        "  tokens = tokenizer.convert_ids_to_tokens(input_ids.flatten())\n",
        "  result = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True,output_attentions=True)\n",
        "  hs = result[1]\n",
        "  mask_hidden_state = result[0].squeeze(0)[1]\n",
        "\n",
        "  softmax = torch.nn.Softmax(dim=0)\n",
        "  torch.set_grad_enabled(True)\n",
        "\n",
        "  probs = softmax(mask_hidden_state)\n",
        "\n",
        "  he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "  she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "  # 1 he 0 she\n",
        "  index = np.argmax(probs.tolist())#he_id #if mask_hidden_state[he_id].item()>mask_hidden_state[she_id].item() else she_id\n",
        "\n",
        "  # blk_id = layer id\n",
        "  kwargs = {\"alpha\": 1}\n",
        "\n",
        "  # turn the binary result[0] into real category (with max prob) tensor one_hot\n",
        "  one_hot = np.zeros((1, mask_hidden_state.size()[-1]), dtype=np.float32) # array([[0., 0.]], dtype=float32)\n",
        "  one_hot[0, index] = 1 # array([[1., 0.]], dtype=float32)\n",
        "  one_hot_vector = one_hot\n",
        "  one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
        "  one_hot = torch.sum(one_hot.to(device) * mask_hidden_state) #tensor(1.9705, device='cuda:0', grad_fn=<SumBackward0>)\n",
        "  for blk_id in range(nlayer):\n",
        "    hs[blk_id].retain_grad()\n",
        "\n",
        "  model.zero_grad()\n",
        "  one_hot.backward(retain_graph=True)\n",
        "\n",
        "\n",
        "  mask_id=1\n",
        "  AttCAT = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "  raws = []\n",
        "  CAT_h = []\n",
        "  CAT=[]\n",
        "  for blk_id in range(nlayer):\n",
        "      hs_grads = hs[blk_id].grad\n",
        "      # # [batchsize, head, num_token, num_token].squeeze -- [head, num_token, num_token]\n",
        "      raw = result[2][blk_id].squeeze(0) # shape torch.Size([12, 13, 13])\n",
        "      avghead = raw.mean(dim=0)\n",
        "      att = avghead[mask_id] # torch.Size([13]) Q_mask_id\n",
        "\n",
        "      # torch.Size([1, 13, 768])\n",
        "      # hidden states average pooling\n",
        "      cat = (hs_grads * hs[blk_id]).sum(dim=-1).squeeze(0)\n",
        "      CAT.append(cat.cpu().detach().numpy())\n",
        "      cat = cat * att # hardmard product\n",
        "\n",
        "      #avgtoken = avgtoken * cat\n",
        "\n",
        "      cat = cat.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "      AttCAT.append(cat) # torch.Size([13])\n",
        "      raws.append(att.cpu().detach().numpy())\n",
        "\n",
        "  AttCAT = np.array(AttCAT)[:,1:-1]\n",
        "\n",
        "  raws = np.array(raws)[:,1:-1]\n",
        "\n",
        "  CAT = np.array(CAT)[:,1:-1]\n",
        "  all_map.append({\"AttCAT\":AttCAT\n",
        "                  ,\"raws\":raws\n",
        "                  ,\"CAT\":CAT\n",
        "                  ,\"lines\":text_batch[id]\n",
        "                  ,\"tokens\":tokens\n",
        "                  ,\"mask\":attention_mask.cpu().detach().numpy()})"
      ],
      "metadata": {
        "id": "bUX-bTDqzNDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/ADJTMP_male_AttCAT.txt\", \"wb\") as handle:\n",
        "  pickle.dump(all_map, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "JpIPSTkMzuFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Att_cat = all_map\n",
        "ismax = np.zeros(len(Att_cat))\n",
        "ratio = np.zeros(len(Att_cat))# the percentage for the word of the whole sentence\n",
        "for i in range(len(Att_cat)):\n",
        "  score = Att_cat[i][\"AttCAT\"].sum(axis=0)[1:].tolist() # impact score without mask\n",
        "  abs_s = [abs(k) for k in score]\n",
        "  ratio[i] = abs_s[2]/sum(abs_s)\n",
        "  ismax[i] = 1 if np.argmax(abs_s)==2 else 0\n",
        "\n",
        "print(\"mean ratio of adj word:\",ratio.mean())\n",
        "print(\"number of samples:\", len(Att_cat))\n",
        "ismax.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xI5tPSGNvrL",
        "outputId": "0d86b2db-0cbe-4ad3-d993-1b36112669d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean ratio of adj word: 0.06595406395775955\n",
            "number of samples: 25\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ADJ2Template_female & ADJ2Template_male\n",
        "* scope: strength & weakness"
      ],
      "metadata": {
        "id": "TfeR4wQLz_U2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class ADJ2Template_female:\n",
        "    def __init__(self):\n",
        "        adj_m = \"powerful, strong, confident, dominant, potent, commanding, assertive, loud, bold, successful, noisy, dynamic\".lower().replace(\" \", \"\").split(',')\n",
        "        adj_f = \"weak, timid, vulnerable, weakness, wispy, yielding, failure, shy, lose, fragile, faintish, pavid\".lower().replace(\" \", \"\").split(',')\n",
        "        self.lines = [re.sub('_',' ',tokenizer.mask_token+' is a '+i+' person.') for i in adj_f]\n",
        "        encoding = tokenizer.batch_encode_plus(self.lines, add_special_tokens=True, max_length=128)\n",
        "        self.examples = encoding[\"input_ids\"]\n",
        "        self.attention_mask = encoding[\"attention_mask\"]\n",
        "        self.getbaseline()\n",
        "        self.get_bias_score_per_layer()\n",
        "\n",
        "    def getbaseline(self):\n",
        "        # get new prob of he/she\n",
        "        self.baseline = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            output = model(vec,attention_mask=mask)\n",
        "            #output = model(vec)\n",
        "            mask_hidden_state = output[0].squeeze(0)[1]\n",
        "            softmax = torch.nn.Softmax(dim=0)\n",
        "            torch.set_grad_enabled(False)\n",
        "            probs = softmax(mask_hidden_state)\n",
        "            # get probability of token 'he'\n",
        "            he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "            #print('he probability', probs[he_id].item())\n",
        "            # get probability of token 'she'\n",
        "            she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "            #print('she probability', probs[she_id].item())\n",
        "            self.baseline.append([probs[he_id].item(), probs[she_id].item()])\n",
        "\n",
        "\n",
        "    def get_bias_score_per_layer(self):\n",
        "        self.bias_score_per_layer = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            bias_mat = np.zeros((nlayer,len(self.examples[i])-2))\n",
        "            # (num_token, 768) @ (768,768)\n",
        "            for layer in range(nlayer):\n",
        "                # get embedding of each layer\n",
        "                output = model(vec,attention_mask=mask)[1][layer+1][0][1:-1]\n",
        "                #output = model(vec)[1][layer+1][0][1:-1]\n",
        "                eigvec = torch.load('./result/DR/eigvecs_'+config+'_wiki_'+str(nsamples)+'_'+str(layer)+'.pt').to(device)\n",
        "\n",
        "                bias = torch.mm(output, eigvec)[:, 0]\n",
        "                bias_mat[layer] = np.array(bias.tolist())\n",
        "            self.bias_score_per_layer.append({\"sentence\":self.lines[i],\"tokens\":self.examples[i],\"mat\":bias_mat})\n",
        "        return self.bias_score_per_layer\n",
        "\n",
        "template = ADJ2Template_female()\n"
      ],
      "metadata": {
        "id": "VtUlkMGyz_g2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/ADJTMP2_female_prob.txt\", \"wb\") as handle:\n",
        "  pickle.dump(template.baseline, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "MorHlVqN7MFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/ADJTMP2_female_DR.txt\", \"wb\") as handle:\n",
        "  pickle.dump(template.bias_score_per_layer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "lHSW7SEu9L-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_batch = [i for i in template.lines]\n",
        "\n",
        "all_map = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "\n",
        "\n",
        "for id in range(len(template.examples)):\n",
        "\n",
        "  encoding  = tokenizer.encode_plus(text_batch[id], add_special_tokens=True, max_length=128,return_tensors=\"pt\")\n",
        "  input_ids = encoding['input_ids'].to(device)\n",
        "  attention_mask = encoding['attention_mask'].to(device)\n",
        "  attention_mask[0][0] = 0\n",
        "  attention_mask[0][-1] = 0\n",
        "  tokens = tokenizer.convert_ids_to_tokens(input_ids.flatten())\n",
        "  result = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True,output_attentions=True)\n",
        "  hs = result[1]\n",
        "  mask_hidden_state = result[0].squeeze(0)[1]\n",
        "\n",
        "  softmax = torch.nn.Softmax(dim=0)\n",
        "  torch.set_grad_enabled(True)\n",
        "\n",
        "  probs = softmax(mask_hidden_state)\n",
        "\n",
        "  he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "  she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "  # 1 he 0 she\n",
        "  index = np.argmax(probs.tolist())#he_id #if mask_hidden_state[he_id].item()>mask_hidden_state[she_id].item() else she_id\n",
        "\n",
        "  # blk_id = layer id\n",
        "  kwargs = {\"alpha\": 1}\n",
        "\n",
        "  # turn the binary result[0] into real category (with max prob) tensor one_hot\n",
        "  one_hot = np.zeros((1, mask_hidden_state.size()[-1]), dtype=np.float32) # array([[0., 0.]], dtype=float32)\n",
        "  one_hot[0, index] = 1 # array([[1., 0.]], dtype=float32)\n",
        "  one_hot_vector = one_hot\n",
        "  one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
        "  one_hot = torch.sum(one_hot.to(device) * mask_hidden_state) #tensor(1.9705, device='cuda:0', grad_fn=<SumBackward0>)\n",
        "  for blk_id in range(nlayer):\n",
        "    hs[blk_id].retain_grad()\n",
        "\n",
        "  model.zero_grad()\n",
        "  one_hot.backward(retain_graph=True)\n",
        "\n",
        "\n",
        "  mask_id=1\n",
        "  AttCAT = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "  raws = []\n",
        "  CAT_h = []\n",
        "  CAT=[]\n",
        "  for blk_id in range(nlayer):\n",
        "      hs_grads = hs[blk_id].grad\n",
        "      # # [batchsize, head, num_token, num_token].squeeze -- [head, num_token, num_token]\n",
        "      raw = result[2][blk_id].squeeze(0) # shape torch.Size([12, 13, 13])\n",
        "      avghead = raw.mean(dim=0)\n",
        "      att = avghead[mask_id] # torch.Size([13]) Q_mask_id\n",
        "\n",
        "      # torch.Size([1, 13, 768])\n",
        "      # hidden states average pooling\n",
        "      cat = (hs_grads * hs[blk_id]).sum(dim=-1).squeeze(0)\n",
        "      CAT.append(cat.cpu().detach().numpy())\n",
        "      cat = cat * att # hardmard product\n",
        "\n",
        "      #avgtoken = avgtoken * cat\n",
        "\n",
        "      cat = cat.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "      AttCAT.append(cat) # torch.Size([13])\n",
        "      raws.append(att.cpu().detach().numpy())\n",
        "\n",
        "  AttCAT = np.array(AttCAT)[:,1:-1]\n",
        "\n",
        "  raws = np.array(raws)[:,1:-1]\n",
        "\n",
        "  CAT = np.array(CAT)[:,1:-1]\n",
        "  all_map.append({\"AttCAT\":AttCAT\n",
        "                  ,\"raws\":raws\n",
        "                  ,\"CAT\":CAT\n",
        "                  ,\"lines\":text_batch[id]\n",
        "                  ,\"tokens\":tokens\n",
        "                  ,\"mask\":attention_mask.cpu().detach().numpy()})"
      ],
      "metadata": {
        "id": "yZm8Jlwq7UuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/ADJTMP2_female_AttCAT.txt\", \"wb\") as handle:\n",
        "  pickle.dump(all_map, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "cWPJn1_T8vnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Att_cat = all_map\n",
        "ismax = np.zeros(len(Att_cat))\n",
        "ratio = np.zeros(len(Att_cat))# the percentage for the word of the whole sentence\n",
        "for i in range(len(Att_cat)):\n",
        "  score = Att_cat[i][\"AttCAT\"].sum(axis=0)[1:].tolist() # impact score without mask\n",
        "  abs_s = [abs(k) for k in score]\n",
        "  ratio[i] = abs_s[2]/sum(abs_s)\n",
        "  ismax[i] = 1 if np.argmax(abs_s)==2 else 0\n",
        "\n",
        "print(\"mean ratio of adj word:\",ratio.mean())\n",
        "print(\"number of samples:\", len(Att_cat))\n",
        "ismax.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD8J8vaLOCxa",
        "outputId": "f4168f35-fd4a-4662-b0fc-d47fec438b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean ratio of adj word: 0.09338081152677509\n",
            "number of samples: 12\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class ADJ2Template_male:\n",
        "    def __init__(self):\n",
        "        adj_m = \"powerful, strong, confident, dominant, potent, commanding, assertive, loud, bold, successful, noisy, dynamic\".lower().replace(\" \", \"\").split(',')\n",
        "        adj_f = \"weak, timid, vulnerable, weakness, wispy, yielding, failure, shy, lose, fragile, faintish, pavid\".lower().replace(\" \", \"\").split(',')\n",
        "        self.lines = [re.sub('_',' ',tokenizer.mask_token+' is a '+i+' person.') for i in adj_m]\n",
        "        encoding = tokenizer.batch_encode_plus(self.lines, add_special_tokens=True, max_length=128)\n",
        "        self.examples = encoding[\"input_ids\"]\n",
        "        self.attention_mask = encoding[\"attention_mask\"]\n",
        "        self.getbaseline()\n",
        "        self.get_bias_score_per_layer()\n",
        "\n",
        "    def getbaseline(self):\n",
        "        # get new prob of he/she\n",
        "        self.baseline = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            output = model(vec,attention_mask=mask)\n",
        "            #output = model(vec)\n",
        "            mask_hidden_state = output[0].squeeze(0)[1]\n",
        "            softmax = torch.nn.Softmax(dim=0)\n",
        "            torch.set_grad_enabled(False)\n",
        "            probs = softmax(mask_hidden_state)\n",
        "            # get probability of token 'he'\n",
        "            he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "            #print('he probability', probs[he_id].item())\n",
        "            # get probability of token 'she'\n",
        "            she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "            #print('she probability', probs[she_id].item())\n",
        "            self.baseline.append([probs[he_id].item(), probs[she_id].item()])\n",
        "\n",
        "\n",
        "    def get_bias_score_per_layer(self):\n",
        "        self.bias_score_per_layer = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            bias_mat = np.zeros((nlayer,len(self.examples[i])-2))\n",
        "            # (num_token, 768) @ (768,768)\n",
        "            for layer in range(nlayer):\n",
        "                # get embedding of each layer\n",
        "                output = model(vec,attention_mask=mask)[1][layer+1][0][1:-1]\n",
        "                #output = model(vec)[1][layer+1][0][1:-1]\n",
        "                eigvec = torch.load('./result/DR/eigvecs_'+config+'_wiki_'+str(nsamples)+'_'+str(layer)+'.pt').to(device)\n",
        "\n",
        "                bias = torch.mm(output, eigvec)[:, 0]\n",
        "                bias_mat[layer] = np.array(bias.tolist())\n",
        "            self.bias_score_per_layer.append({\"sentence\":self.lines[i],\"tokens\":self.examples[i],\"mat\":bias_mat})\n",
        "        return self.bias_score_per_layer\n",
        "\n",
        "template = ADJ2Template_male()\n"
      ],
      "metadata": {
        "id": "9o_i9XLn8_4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/ADJTMP2_male_DR.txt\", \"wb\") as handle:\n",
        "  pickle.dump(template.bias_score_per_layer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "vRTQUy869ADk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/ADJTMP2_male_prob.txt\", \"wb\") as handle:\n",
        "  pickle.dump(template.baseline, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "4MGZNuqY9AL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_batch = [i for i in template.lines]\n",
        "\n",
        "all_map = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "\n",
        "\n",
        "for id in range(len(template.examples)):\n",
        "\n",
        "  encoding  = tokenizer.encode_plus(text_batch[id], add_special_tokens=True, max_length=128,return_tensors=\"pt\")\n",
        "  input_ids = encoding['input_ids'].to(device)\n",
        "  attention_mask = encoding['attention_mask'].to(device)\n",
        "  attention_mask[0][0] = 0\n",
        "  attention_mask[0][-1] = 0\n",
        "  tokens = tokenizer.convert_ids_to_tokens(input_ids.flatten())\n",
        "  result = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True,output_attentions=True)\n",
        "  hs = result[1]\n",
        "  mask_hidden_state = result[0].squeeze(0)[1]\n",
        "\n",
        "  softmax = torch.nn.Softmax(dim=0)\n",
        "  torch.set_grad_enabled(True)\n",
        "\n",
        "  probs = softmax(mask_hidden_state)\n",
        "\n",
        "  he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "  she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "  # 1 he 0 she\n",
        "  index = np.argmax(probs.tolist())#he_id #if mask_hidden_state[he_id].item()>mask_hidden_state[she_id].item() else she_id\n",
        "\n",
        "  # blk_id = layer id\n",
        "  kwargs = {\"alpha\": 1}\n",
        "\n",
        "  # turn the binary result[0] into real category (with max prob) tensor one_hot\n",
        "  one_hot = np.zeros((1, mask_hidden_state.size()[-1]), dtype=np.float32) # array([[0., 0.]], dtype=float32)\n",
        "  one_hot[0, index] = 1 # array([[1., 0.]], dtype=float32)\n",
        "  one_hot_vector = one_hot\n",
        "  one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
        "  one_hot = torch.sum(one_hot.to(device) * mask_hidden_state) #tensor(1.9705, device='cuda:0', grad_fn=<SumBackward0>)\n",
        "  for blk_id in range(nlayer):\n",
        "    hs[blk_id].retain_grad()\n",
        "\n",
        "  model.zero_grad()\n",
        "  one_hot.backward(retain_graph=True)\n",
        "\n",
        "\n",
        "  mask_id=1\n",
        "  AttCAT = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "  raws = []\n",
        "  CAT_h = []\n",
        "  CAT=[]\n",
        "  for blk_id in range(nlayer):\n",
        "      hs_grads = hs[blk_id].grad\n",
        "      # # [batchsize, head, num_token, num_token].squeeze -- [head, num_token, num_token]\n",
        "      raw = result[2][blk_id].squeeze(0) # shape torch.Size([12, 13, 13])\n",
        "      avghead = raw.mean(dim=0)\n",
        "      att = avghead[mask_id] # torch.Size([13]) Q_mask_id\n",
        "\n",
        "      # torch.Size([1, 13, 768])\n",
        "      # hidden states average pooling\n",
        "      cat = (hs_grads * hs[blk_id]).sum(dim=-1).squeeze(0)\n",
        "      CAT.append(cat.cpu().detach().numpy())\n",
        "      cat = cat * att # hardmard product\n",
        "\n",
        "      #avgtoken = avgtoken * cat\n",
        "\n",
        "      cat = cat.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "      AttCAT.append(cat) # torch.Size([13])\n",
        "      raws.append(att.cpu().detach().numpy())\n",
        "\n",
        "  AttCAT = np.array(AttCAT)[:,1:-1]\n",
        "\n",
        "  raws = np.array(raws)[:,1:-1]\n",
        "\n",
        "  CAT = np.array(CAT)[:,1:-1]\n",
        "  all_map.append({\"AttCAT\":AttCAT\n",
        "                  ,\"raws\":raws\n",
        "                  ,\"CAT\":CAT\n",
        "                  ,\"lines\":text_batch[id]\n",
        "                  ,\"tokens\":tokens\n",
        "                  ,\"mask\":attention_mask.cpu().detach().numpy()})"
      ],
      "metadata": {
        "id": "nEzePttJ-D7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/ADJTMP2_male_AttCAT.txt\", \"wb\") as handle:\n",
        "  pickle.dump(all_map, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "En7m85j2-EDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Att_cat = all_map\n",
        "ismax = np.zeros(len(Att_cat))\n",
        "ratio = np.zeros(len(Att_cat))# the percentage for the word of the whole sentence\n",
        "for i in range(len(Att_cat)):\n",
        "  score = Att_cat[i][\"AttCAT\"].sum(axis=0)[1:].tolist() # impact score without mask\n",
        "  abs_s = [abs(k) for k in score]\n",
        "  ratio[i] = abs_s[2]/sum(abs_s)\n",
        "  ismax[i] = 1 if np.argmax(abs_s)==2 else 0\n",
        "\n",
        "print(\"mean ratio of adj word:\",ratio.mean())\n",
        "print(\"number of samples:\", len(Att_cat))\n",
        "ismax.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz-7s_aVPryR",
        "outputId": "d4adad20-1f8f-43e2-9f59-ef73580b21b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean ratio of adj word: 0.12444828318811531\n",
            "number of samples: 12\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# template-NOUNTMP\n",
        "* [mask] is good at [mask]."
      ],
      "metadata": {
        "id": "XUKKd58d_bw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NTemplate_log"
      ],
      "metadata": {
        "id": "yh6YbrXyAQTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NTemplate_log:\n",
        "    def __init__(self):\n",
        "        # mask is good at mask.\n",
        "        self.lines_prior = [re.sub('_',' ',tokenizer.mask_token+' is good at '+tokenizer.mask_token+'.')]\n",
        "        encoding = tokenizer.batch_encode_plus(self.lines_prior, add_special_tokens=True, max_length=128)\n",
        "        self.examples_prior = encoding[\"input_ids\"]\n",
        "        self.attention_mask = encoding[\"attention_mask\"]\n",
        "        self.getbaseline()\n",
        "\n",
        "    def getbaseline(self):\n",
        "        # return probability of he/she in first token\n",
        "        def get_probs(example=self.examples_prior,mask = self.attention_mask):\n",
        "          baseline = []\n",
        "          for i in range(len(self.examples_prior)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples_prior[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            output = model(vec,attention_mask=mask)\n",
        "            #output = model(vec)\n",
        "            mask_hidden_state = output[0].squeeze(0)[1]\n",
        "            softmax = torch.nn.Softmax(dim=0)\n",
        "            torch.set_grad_enabled(False)\n",
        "            probs = softmax(mask_hidden_state)\n",
        "            # get probability of token 'he'\n",
        "            he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "            #print('he probability', probs[he_id].item())\n",
        "            # get probability of token 'she'\n",
        "            she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "            #print('she probability', probs[she_id].item())\n",
        "            baseline.append([probs[he_id].item(), probs[she_id].item()])\n",
        "          return baseline\n",
        "        self.baseline_prior = get_probs(self.examples_prior,self.attention_mask)\n",
        "\n",
        "n_template_log = NTemplate_log()\n",
        "n_template_log.baseline_prior"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQV2aIKi_bFL",
        "outputId": "50b036e4-1fd3-4183-9096-94eb489ddd4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.03548009321093559, 0.017635375261306763]]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NTemplate_female & NTemplate_male"
      ],
      "metadata": {
        "id": "LXqmdWnnBqwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class NTemplate_female:\n",
        "    def __init__(self):\n",
        "        n_m = 'math, algebra, geometry, calculus, equations, computation, numbers, addition, science, technology, physics, chemistry, Einstein, NASA, experiment, astronomy'.lower().replace(\" \", \"\").split(',')\n",
        "        n_f = 'poetry, art, dance, literature, novel, symphony, drama, sculpture'.lower().replace(\" \", \"\").split(',')\n",
        "        self.lines = [re.sub('_',' ',tokenizer.mask_token+' is good at '+i+'.') for i in n_f]\n",
        "        encoding = tokenizer.batch_encode_plus(self.lines, add_special_tokens=True, max_length=128)\n",
        "        self.examples = encoding[\"input_ids\"]\n",
        "        self.attention_mask = encoding[\"attention_mask\"]\n",
        "        self.getbaseline()\n",
        "        self.get_bias_score_per_layer()\n",
        "\n",
        "    def getbaseline(self):\n",
        "        # get new prob of he/she\n",
        "        self.baseline = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            output = model(vec,attention_mask=mask)\n",
        "            #output = model(vec)\n",
        "            mask_hidden_state = output[0].squeeze(0)[1]\n",
        "            softmax = torch.nn.Softmax(dim=0)\n",
        "            torch.set_grad_enabled(False)\n",
        "            probs = softmax(mask_hidden_state)\n",
        "            # get probability of token 'he'\n",
        "            he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "            #print('he probability', probs[he_id].item())\n",
        "            # get probability of token 'she'\n",
        "            she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "            #print('she probability', probs[she_id].item())\n",
        "            self.baseline.append([probs[he_id].item(), probs[she_id].item()])\n",
        "\n",
        "    def get_bias_score_per_layer(self):\n",
        "        self.bias_score_per_layer = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            bias_mat = np.zeros((nlayer,len(self.examples[i])-2))\n",
        "            # (num_token, 768) @ (768,768)\n",
        "            for layer in range(nlayer):\n",
        "                # get embedding of each layer\n",
        "                output = model(vec,attention_mask=mask)[1][layer+1][0][1:-1]\n",
        "                #output = model(vec)[1][layer+1][0][1:-1]\n",
        "                eigvec = torch.load('./result/DR/eigvecs_'+config+'_wiki_'+str(nsamples)+'_'+str(layer)+'.pt').to(device)\n",
        "\n",
        "                bias = torch.mm(output, eigvec)[:, 0]\n",
        "                bias_mat[layer] = np.array(bias.tolist())\n",
        "            self.bias_score_per_layer.append({\"sentence\":self.lines[i],\"tokens\":self.examples[i],\"mat\":bias_mat})\n",
        "        return self.bias_score_per_layer\n",
        "\n",
        "template = NTemplate_female()\n"
      ],
      "metadata": {
        "id": "xVLSa7Vx_bPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/NTMP_female_prob.txt\", \"wb\") as handle:\n",
        "  pickle.dump(template.baseline, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "Yb4c6b6CCI7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/NTMP_female_DR.txt\", \"wb\") as handle:\n",
        "  pickle.dump(template.bias_score_per_layer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "RdhVOzNUBkna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_batch = [i for i in template.lines]\n",
        "\n",
        "all_map = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "\n",
        "\n",
        "for id in range(len(template.examples)):\n",
        "\n",
        "  encoding  = tokenizer.encode_plus(text_batch[id], add_special_tokens=True, max_length=128,return_tensors=\"pt\")\n",
        "  input_ids = encoding['input_ids'].to(device)\n",
        "  attention_mask = encoding['attention_mask'].to(device)\n",
        "  attention_mask[0][0] = 0\n",
        "  attention_mask[0][-1] = 0\n",
        "  tokens = tokenizer.convert_ids_to_tokens(input_ids.flatten())\n",
        "  result = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True,output_attentions=True)\n",
        "  hs = result[1]\n",
        "  mask_hidden_state = result[0].squeeze(0)[1]\n",
        "\n",
        "  softmax = torch.nn.Softmax(dim=0)\n",
        "  torch.set_grad_enabled(True)\n",
        "\n",
        "  probs = softmax(mask_hidden_state)\n",
        "\n",
        "  he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "  she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "  # 1 he 0 she\n",
        "  index = np.argmax(probs.tolist())#he_id #if mask_hidden_state[he_id].item()>mask_hidden_state[she_id].item() else she_id\n",
        "\n",
        "  # blk_id = layer id\n",
        "  kwargs = {\"alpha\": 1}\n",
        "\n",
        "  # turn the binary result[0] into real category (with max prob) tensor one_hot\n",
        "  one_hot = np.zeros((1, mask_hidden_state.size()[-1]), dtype=np.float32) # array([[0., 0.]], dtype=float32)\n",
        "  one_hot[0, index] = 1 # array([[1., 0.]], dtype=float32)\n",
        "  one_hot_vector = one_hot\n",
        "  one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
        "  one_hot = torch.sum(one_hot.to(device) * mask_hidden_state) #tensor(1.9705, device='cuda:0', grad_fn=<SumBackward0>)\n",
        "  for blk_id in range(nlayer):\n",
        "    hs[blk_id].retain_grad()\n",
        "\n",
        "  model.zero_grad()\n",
        "  one_hot.backward(retain_graph=True)\n",
        "\n",
        "\n",
        "  mask_id=1\n",
        "  AttCAT = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "  raws = []\n",
        "  CAT_h = []\n",
        "  CAT=[]\n",
        "  for blk_id in range(nlayer):\n",
        "      hs_grads = hs[blk_id].grad\n",
        "      # # [batchsize, head, num_token, num_token].squeeze -- [head, num_token, num_token]\n",
        "      raw = result[2][blk_id].squeeze(0) # shape torch.Size([12, 13, 13])\n",
        "      avghead = raw.mean(dim=0)\n",
        "      att = avghead[mask_id] # torch.Size([13]) Q_mask_id\n",
        "\n",
        "      # torch.Size([1, 13, 768])\n",
        "      # hidden states average pooling\n",
        "      cat = (hs_grads * hs[blk_id]).sum(dim=-1).squeeze(0)\n",
        "      CAT.append(cat.cpu().detach().numpy())\n",
        "      cat = cat * att # hardmard product\n",
        "\n",
        "      #avgtoken = avgtoken * cat\n",
        "\n",
        "      cat = cat.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "      AttCAT.append(cat) # torch.Size([13])\n",
        "      raws.append(att.cpu().detach().numpy())\n",
        "\n",
        "  AttCAT = np.array(AttCAT)[:,1:-1]\n",
        "\n",
        "  raws = np.array(raws)[:,1:-1]\n",
        "\n",
        "  CAT = np.array(CAT)[:,1:-1]\n",
        "  all_map.append({\"AttCAT\":AttCAT\n",
        "                  ,\"raws\":raws\n",
        "                  ,\"CAT\":CAT\n",
        "                  ,\"lines\":text_batch[id]\n",
        "                  ,\"tokens\":tokens})"
      ],
      "metadata": {
        "id": "Xbg-BOi3CTzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/NTMP_female_AttCAT.txt\", \"wb\") as handle:\n",
        "  pickle.dump(all_map, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "Fl4Oqk2iCT8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Att_cat = all_map\n",
        "ismax = np.zeros(len(Att_cat))\n",
        "ratio = np.zeros(len(Att_cat))# the percentage for the word of the whole sentence\n",
        "for i in range(len(Att_cat)):\n",
        "  score = Att_cat[i][\"AttCAT\"].sum(axis=0)[1:].tolist() # impact score without mask\n",
        "  abs_s = [abs(k) for k in score]\n",
        "  ratio[i] = abs_s[2]/sum(abs_s)\n",
        "  ismax[i] = 1 if np.argmax(abs_s)==2 else 0\n",
        "\n",
        "print(\"mean ratio of noun word:\",ratio.mean())\n",
        "print(\"number of samples:\", len(Att_cat))\n",
        "ismax.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQDkkfDvP8T7",
        "outputId": "da4926d5-bc34-43c5-f93a-50587a22b254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean ratio of noun word: 0.07112911969655454\n",
            "number of samples: 8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class NTemplate_male:\n",
        "    def __init__(self):\n",
        "        n_m = 'math, algebra, geometry, calculus, equations, computation, numbers, addition, science, technology, physics, chemistry, Einstein, NASA, experiment, astronomy'.lower().replace(\" \", \"\").split(',')\n",
        "        n_f = 'poetry, art, dance, literature, novel, symphony, drama, sculpture'.lower().replace(\" \", \"\").split(',')\n",
        "        self.lines = [re.sub('_',' ',tokenizer.mask_token+' is good at '+i+'.') for i in n_m]\n",
        "        encoding = tokenizer.batch_encode_plus(self.lines, add_special_tokens=True, max_length=128)\n",
        "        self.examples = encoding[\"input_ids\"]\n",
        "        self.attention_mask = encoding[\"attention_mask\"]\n",
        "        self.getbaseline()\n",
        "        self.get_bias_score_per_layer()\n",
        "\n",
        "    def getbaseline(self):\n",
        "        # get new prob of he/she\n",
        "        self.baseline = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            output = model(vec,attention_mask=mask)\n",
        "            #output = model(vec)\n",
        "            mask_hidden_state = output[0].squeeze(0)[1]\n",
        "            softmax = torch.nn.Softmax(dim=0)\n",
        "            torch.set_grad_enabled(False)\n",
        "            probs = softmax(mask_hidden_state)\n",
        "            # get probability of token 'he'\n",
        "            he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "            #print('he probability', probs[he_id].item())\n",
        "            # get probability of token 'she'\n",
        "            she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "            #print('she probability', probs[she_id].item())\n",
        "            self.baseline.append([probs[he_id].item(), probs[she_id].item()])\n",
        "\n",
        "    def get_bias_score_per_layer(self):\n",
        "        self.bias_score_per_layer = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            bias_mat = np.zeros((nlayer,len(self.examples[i])-2))\n",
        "            # (num_token, 768) @ (768,768)\n",
        "            for layer in range(nlayer):\n",
        "                # get embedding of each layer\n",
        "                output = model(vec,attention_mask=mask)[1][layer+1][0][1:-1]\n",
        "                #output = model(vec)[1][layer+1][0][1:-1]\n",
        "                eigvec = torch.load('./result/DR/eigvecs_'+config+'_wiki_'+str(nsamples)+'_'+str(layer)+'.pt').to(device)\n",
        "\n",
        "                bias = torch.mm(output, eigvec)[:, 0]\n",
        "                bias_mat[layer] = np.array(bias.tolist())\n",
        "            self.bias_score_per_layer.append({\"sentence\":self.lines[i],\"tokens\":self.examples[i],\"mat\":bias_mat})\n",
        "        return self.bias_score_per_layer\n",
        "\n",
        "template = NTemplate_male()\n"
      ],
      "metadata": {
        "id": "xp1jZt9YCkks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/NTMP_male_prob.txt\", \"wb\") as handle:\n",
        "  pickle.dump(template.baseline, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "S81Rfrp_DD5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/NTMP_male_DR.txt\", \"wb\") as handle:\n",
        "  pickle.dump(template.bias_score_per_layer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "db_312MNDGQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_batch = [i for i in template.lines]\n",
        "\n",
        "all_map = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "\n",
        "\n",
        "for id in range(len(template.examples)):\n",
        "\n",
        "  encoding  = tokenizer.encode_plus(text_batch[id], add_special_tokens=True, max_length=128,return_tensors=\"pt\")\n",
        "  input_ids = encoding['input_ids'].to(device)\n",
        "  attention_mask = encoding['attention_mask'].to(device)\n",
        "  attention_mask[0][0] = 0\n",
        "  attention_mask[0][-1] = 0\n",
        "  tokens = tokenizer.convert_ids_to_tokens(input_ids.flatten())\n",
        "  result = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True,output_attentions=True)\n",
        "  hs = result[1]\n",
        "  mask_hidden_state = result[0].squeeze(0)[1]\n",
        "\n",
        "  softmax = torch.nn.Softmax(dim=0)\n",
        "  torch.set_grad_enabled(True)\n",
        "\n",
        "  probs = softmax(mask_hidden_state)\n",
        "\n",
        "  he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "  she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "  # 1 he 0 she\n",
        "  index = np.argmax(probs.tolist())#he_id #if mask_hidden_state[he_id].item()>mask_hidden_state[she_id].item() else she_id\n",
        "\n",
        "  # blk_id = layer id\n",
        "  kwargs = {\"alpha\": 1}\n",
        "\n",
        "  # turn the binary result[0] into real category (with max prob) tensor one_hot\n",
        "  one_hot = np.zeros((1, mask_hidden_state.size()[-1]), dtype=np.float32) # array([[0., 0.]], dtype=float32)\n",
        "  one_hot[0, index] = 1 # array([[1., 0.]], dtype=float32)\n",
        "  one_hot_vector = one_hot\n",
        "  one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
        "  one_hot = torch.sum(one_hot.to(device) * mask_hidden_state) #tensor(1.9705, device='cuda:0', grad_fn=<SumBackward0>)\n",
        "  for blk_id in range(nlayer):\n",
        "    hs[blk_id].retain_grad()\n",
        "\n",
        "  model.zero_grad()\n",
        "  one_hot.backward(retain_graph=True)\n",
        "\n",
        "\n",
        "  mask_id=1\n",
        "  AttCAT = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "  raws = []\n",
        "  CAT_h = []\n",
        "  CAT=[]\n",
        "  for blk_id in range(nlayer):\n",
        "      hs_grads = hs[blk_id].grad\n",
        "      # # [batchsize, head, num_token, num_token].squeeze -- [head, num_token, num_token]\n",
        "      raw = result[2][blk_id].squeeze(0) # shape torch.Size([12, 13, 13])\n",
        "      avghead = raw.mean(dim=0)\n",
        "      att = avghead[mask_id] # torch.Size([13]) Q_mask_id\n",
        "\n",
        "      # torch.Size([1, 13, 768])\n",
        "      # hidden states average pooling\n",
        "      cat = (hs_grads * hs[blk_id]).sum(dim=-1).squeeze(0)\n",
        "      CAT.append(cat.cpu().detach().numpy())\n",
        "      cat = cat * att # hardmard product\n",
        "\n",
        "      #avgtoken = avgtoken * cat\n",
        "\n",
        "      cat = cat.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "      AttCAT.append(cat) # torch.Size([13])\n",
        "      raws.append(att.cpu().detach().numpy())\n",
        "\n",
        "  AttCAT = np.array(AttCAT)[:,1:-1]\n",
        "\n",
        "  raws = np.array(raws)[:,1:-1]\n",
        "\n",
        "  CAT = np.array(CAT)[:,1:-1]\n",
        "  all_map.append({\"AttCAT\":AttCAT\n",
        "                  ,\"raws\":raws\n",
        "                  ,\"CAT\":CAT\n",
        "                  ,\"lines\":text_batch[id]\n",
        "                  ,\"tokens\":tokens})"
      ],
      "metadata": {
        "id": "PeGAKNSZDKa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./result/NTMP_male_AttCAT.txt\", \"wb\") as handle:\n",
        "  pickle.dump(all_map, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "gmaIOPYXCkxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Att_cat = all_map\n",
        "ismax = np.zeros(len(Att_cat))\n",
        "ratio = np.zeros(len(Att_cat))# the percentage for the word of the whole sentence\n",
        "for i in range(len(Att_cat)):\n",
        "  score = Att_cat[i][\"AttCAT\"].sum(axis=0)[1:].tolist() # impact score without mask\n",
        "  abs_s = [abs(k) for k in score]\n",
        "  ratio[i] = abs_s[2]/sum(abs_s)\n",
        "  ismax[i] = 1 if np.argmax(abs_s)==2 else 0\n",
        "\n",
        "print(\"mean ratio of noun word:\",ratio.mean())\n",
        "print(\"number of samples:\", len(Att_cat))\n",
        "ismax.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3TdxqqyCk7Q",
        "outputId": "e1f08e9a-f1d5-47fc-a968-75058636fe81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean ratio of noun word: 0.07330298397827326\n",
            "number of samples: 16\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# bias_visualization paper template\n",
        "* from Densray paper\n"
      ],
      "metadata": {
        "id": "XwfECS8cvrIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('./newresult/bias_dict 2.txt', 'rb') as file:\n",
        "    bias_mat_mask = pickle.load(file)\n",
        "bias_mat_mask[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9IzaJSmwNw2",
        "outputId": "c61af7a6-3197-49eb-8d1e-7741e77ce3be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': '[MASK] is the doctor here.',\n",
              " 'tokens': [101, 103, 2003, 1996, 3460, 2182, 1012, 102],\n",
              " 'mat': array([[-1.23598933e-01,  2.85372078e-01,  2.22296894e-01,\n",
              "          6.04331374e-01,  4.59932327e-01,  3.01609218e-01],\n",
              "        [-1.21629611e-03, -1.55912548e-01, -2.44785875e-01,\n",
              "         -7.83474922e-01, -4.81366992e-01, -3.48055720e-01],\n",
              "        [ 2.72217572e-01, -2.14662179e-02,  2.74740785e-01,\n",
              "          6.62678361e-01,  9.85262096e-01,  4.40110385e-01],\n",
              "        [ 7.10669518e-01,  2.84516215e-01,  4.06405896e-01,\n",
              "          1.08275723e+00,  8.07089984e-01,  3.93873096e-01],\n",
              "        [ 5.99127293e-01,  4.87333894e-01,  5.77009678e-01,\n",
              "          1.49719763e+00,  7.50395298e-01,  5.47433794e-01],\n",
              "        [ 9.20589626e-01,  1.05759621e+00,  9.08655643e-01,\n",
              "          1.74316430e+00,  1.13984680e+00,  4.87401366e-01],\n",
              "        [-7.47949481e-01, -8.91177058e-01, -8.74879897e-01,\n",
              "         -1.58309412e+00, -9.93537188e-01, -3.38357389e-01],\n",
              "        [ 1.21197116e+00,  1.11819553e+00,  1.21042275e+00,\n",
              "          1.67539752e+00,  8.34347367e-01,  7.75635719e-01],\n",
              "        [-1.57276642e+00, -1.36851060e+00, -1.63458133e+00,\n",
              "         -1.81536984e+00, -1.17456484e+00, -6.21300757e-01],\n",
              "        [-1.54349732e+00, -1.38066006e+00, -1.59462392e+00,\n",
              "         -1.63191247e+00, -1.10651970e+00, -4.72026855e-01],\n",
              "        [ 1.18524814e+00,  1.27523184e+00,  1.53241026e+00,\n",
              "          1.52699542e+00,  9.21562552e-01,  1.38294160e-01],\n",
              "        [ 3.68603468e-01,  3.74823064e-01,  7.91228354e-01,\n",
              "          4.41831589e-01,  3.72236788e-01,  2.73375243e-01]])}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_batch = [bias_mat_mask[i][\"sentence\"] for i in range(len(bias_mat_mask))]\n",
        "\n",
        "all_map = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "\n",
        "\n",
        "for id in range(len(bias_mat_mask)):\n",
        "\n",
        "  encoding  = tokenizer.encode_plus(text_batch[id], add_special_tokens=True, max_length=128,return_tensors=\"pt\")\n",
        "  input_ids = encoding['input_ids'].to(device)\n",
        "  attention_mask = encoding['attention_mask'].to(device)\n",
        "  attention_mask[0][0] = 0\n",
        "  attention_mask[0][-1] = 0\n",
        "  tokens = tokenizer.convert_ids_to_tokens(input_ids.flatten())\n",
        "  result = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True,output_attentions=True)\n",
        "  hs = result[1]\n",
        "  mask_hidden_state = result[0].squeeze(0)[1]\n",
        "\n",
        "  softmax = torch.nn.Softmax(dim=0)\n",
        "  torch.set_grad_enabled(True)\n",
        "\n",
        "  probs = softmax(mask_hidden_state)\n",
        "\n",
        "  he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "  she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "  # 1 he 0 she\n",
        "  index = np.argmax(probs.tolist())#he_id #if mask_hidden_state[he_id].item()>mask_hidden_state[she_id].item() else she_id\n",
        "\n",
        "  # blk_id = layer id\n",
        "  kwargs = {\"alpha\": 1}\n",
        "\n",
        "  # turn the binary result[0] into real category (with max prob) tensor one_hot\n",
        "  one_hot = np.zeros((1, mask_hidden_state.size()[-1]), dtype=np.float32) # array([[0., 0.]], dtype=float32)\n",
        "  one_hot[0, index] = 1 # array([[1., 0.]], dtype=float32)\n",
        "  one_hot_vector = one_hot\n",
        "  one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
        "  one_hot = torch.sum(one_hot.to(device) * mask_hidden_state) #tensor(1.9705, device='cuda:0', grad_fn=<SumBackward0>)\n",
        "  for blk_id in range(nlayer):\n",
        "    hs[blk_id].retain_grad()\n",
        "\n",
        "  model.zero_grad()\n",
        "  one_hot.backward(retain_graph=True)\n",
        "\n",
        "\n",
        "  mask_id=1\n",
        "  AttCAT = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "  raws = []\n",
        "  CAT_h = []\n",
        "  CAT=[]\n",
        "  for blk_id in range(nlayer):\n",
        "      hs_grads = hs[blk_id].grad\n",
        "      # # [batchsize, head, num_token, num_token].squeeze -- [head, num_token, num_token]\n",
        "      raw = result[2][blk_id].squeeze(0) # shape torch.Size([12, 13, 13])\n",
        "      avghead = raw.mean(dim=0)\n",
        "      att = avghead[mask_id] # torch.Size([13]) Q_mask_id\n",
        "      avgtoken = raw[:,mask_id,:].mean(dim=-1)#.mean(dim=-1)\n",
        "\n",
        "      # torch.Size([1, 13, 768])\n",
        "      # hidden states average pooling\n",
        "      cat = (hs_grads * hs[blk_id]).sum(dim=-1).squeeze(0)\n",
        "      CAT.append(cat.cpu().detach().numpy())\n",
        "      cat = cat * att # hardmard product\n",
        "\n",
        "      #avgtoken = avgtoken * cat\n",
        "\n",
        "      cat = cat.cpu().detach().numpy()\n",
        "      avgtoken = avgtoken.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "      AttCAT.append(cat) # torch.Size([13])\n",
        "      CAT_h.append(avgtoken)\n",
        "      raws.append(att.cpu().detach().numpy())\n",
        "\n",
        "  AttCAT = np.array(AttCAT)[:,1:-1]\n",
        "\n",
        "  raws = np.array(raws)[:,1:-1]\n",
        "\n",
        "  CAT_h = np.array(CAT_h) # 12*12\n",
        "  CAT = np.array(CAT)[:,1:-1]\n",
        "  all_map.append({\"AttCAT\":AttCAT\n",
        "                  ,\"raws\":raws\n",
        "                  ,\"CAT_h\":CAT_h\n",
        "                  ,\"CAT\":CAT\n",
        "                  ,\"lines\":text_batch[id]\n",
        "                  ,\"tokens\":tokens\n",
        "                  ,\"mask\":attention_mask.cpu().detach().numpy()})"
      ],
      "metadata": {
        "id": "DAChWIzDvqfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_map[0]['mask']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGKL_CGnxnzD",
        "outputId": "469a8bac-0360-453a-e403-463544de228b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1, 1, 1, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./newresult/bias_Attcat_example.txt\", \"wb\") as handle:\n",
        "  pickle.dump(all_map, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "Ur4tmNy2xI5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yj0lnEGfxJMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxQ9VX9m370O"
      },
      "source": [
        "# CSP dataset for gender bias\n",
        "https://github.com/nyu-mll/crows-pairs/blob/master/data/crows_pairs_anonymized.csv\n",
        "* Note that have been modified due to suggestions of\\\n",
        " https://www.microsoft.com/en-us/research/uploads/prod/2021/06/The_Salmon_paper.pdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_data = pd.read_csv(\"./data/crows_pairs_anonymized.csv\",index_col=0)\n",
        "df_gender = df_data[df_data['bias_type']==\"gender\"].reset_index()[[\"sent_more\",\"sent_less\",\"stereo_antistereo\"]]\n",
        "print(\"len:\",len(df_gender))\n",
        "df_gender.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "n3r84APEyNRd",
        "outputId": "dba27ea4-87bd-4a9b-8935-4fac1f82ae8c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len: 262\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           sent_more  \\\n",
              "0  His mind wondered if a doctor was behind this ...   \n",
              "1  The man was highly skilled in CAD engineering....   \n",
              "2                     Women don't know how to drive.   \n",
              "3      My mom spent all day cooking for Thanksgiving   \n",
              "4  They said that Bill really wanted a dirtbike f...   \n",
              "\n",
              "                                           sent_less stereo_antistereo  \n",
              "0  His mind wondered if a doctor was behind this ...        antistereo  \n",
              "1  The woman was highly skilled in CAD engineerin...        antistereo  \n",
              "2                             Men know how to drive.            stereo  \n",
              "3     My dad spent all day cooking for Thanksgiving.            stereo  \n",
              "4  They said that Jen really wanted a dirtbike fo...        antistereo  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04deecc3-7287-484f-a5c1-ea9ff317d4f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent_more</th>\n",
              "      <th>sent_less</th>\n",
              "      <th>stereo_antistereo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>His mind wondered if a doctor was behind this ...</td>\n",
              "      <td>His mind wondered if a doctor was behind this ...</td>\n",
              "      <td>antistereo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The man was highly skilled in CAD engineering....</td>\n",
              "      <td>The woman was highly skilled in CAD engineerin...</td>\n",
              "      <td>antistereo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Women don't know how to drive.</td>\n",
              "      <td>Men know how to drive.</td>\n",
              "      <td>stereo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My mom spent all day cooking for Thanksgiving</td>\n",
              "      <td>My dad spent all day cooking for Thanksgiving.</td>\n",
              "      <td>stereo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>They said that Bill really wanted a dirtbike f...</td>\n",
              "      <td>They said that Jen really wanted a dirtbike fo...</td>\n",
              "      <td>antistereo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04deecc3-7287-484f-a5c1-ea9ff317d4f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04deecc3-7287-484f-a5c1-ea9ff317d4f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04deecc3-7287-484f-a5c1-ea9ff317d4f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-47056343-3a9e-4e24-b237-60c4590597db\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47056343-3a9e-4e24-b237-60c4590597db')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-47056343-3a9e-4e24-b237-60c4590597db button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_sentence = []\n",
        "for i in range(len(df_gender)):\n",
        "  words1 = df_gender.iloc[i][\"sent_more\"].split()\n",
        "  words2 = df_gender.iloc[i][\"sent_less\"].split()\n",
        "  different_positions = [\n",
        "      (idx, word1, word2) for idx, (word1, word2) in enumerate(zip(words1, words2)) if word1 != word2]\n",
        "  if(len(different_positions)<=2):\n",
        "    masked_sentence.append(' '.join(tokenizer.mask_token if idx in [position for position, _, _ in different_positions] else word for idx, word in enumerate(words1)))\n"
      ],
      "metadata": {
        "id": "6a2M_abc3RNC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./newresult/CSP_mask_lines.txt\", \"wb\") as handle:\n",
        "  pickle.dump(masked_sentence, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "WIMIEYXxyhZ5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(masked_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCIBIrruOsdV",
        "outputId": "f401087a-43f7-4a1c-d89a-ba5bcd2edf89"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "197"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_sentence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SIZWsRvJ5Y1t",
        "outputId": "b82878ce-1e82-4ec8-e0e4-04597df2bce6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'His mind wondered if a doctor was behind this mess, and whether [MASK] would come forward.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DR scores for CSP dataset\n"
      ],
      "metadata": {
        "id": "S5haleee5FUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class CSPTemplate:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.lines = masked_sentence\n",
        "        encoding = tokenizer.batch_encode_plus(self.lines, add_special_tokens=True, max_length=128)\n",
        "        self.examples = encoding[\"input_ids\"]\n",
        "        self.attention_mask = encoding[\"attention_mask\"]\n",
        "        #self.getbaseline()\n",
        "        self.get_bias_score_per_layer()\n",
        "\n",
        "    def getbaseline(self):\n",
        "        # get new prob of he/she\n",
        "        self.baseline = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            output = model(vec,attention_mask=mask)\n",
        "            #output = model(vec)\n",
        "            mask_hidden_state = output[0].squeeze(0)[1]\n",
        "            softmax = torch.nn.Softmax(dim=0)\n",
        "            torch.set_grad_enabled(False)\n",
        "            probs = softmax(mask_hidden_state)\n",
        "            # get probability of token 'he'\n",
        "            he_id = tokenizer.convert_tokens_to_ids('he')\n",
        "            #print('he probability', probs[he_id].item())\n",
        "            # get probability of token 'she'\n",
        "            she_id = tokenizer.convert_tokens_to_ids('she')\n",
        "            #print('she probability', probs[she_id].item())\n",
        "            self.baseline.append([probs[he_id].item(), probs[she_id].item()])\n",
        "\n",
        "    def get_bias_score_per_layer(self):\n",
        "        self.bias_score_per_layer = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            bias_mat = np.zeros((nlayer,len(self.examples[i])-2))\n",
        "            # (num_token, 768) @ (768,768)\n",
        "            for layer in range(nlayer):\n",
        "                # get embedding of each layer\n",
        "                output = model(vec,attention_mask=mask)[1][layer+1][0][1:-1]\n",
        "                #output = model(vec)[1][layer+1][0][1:-1]\n",
        "                eigvec = torch.load('./result/DR/eigvecs_'+config+'_wiki_'+str(nsamples)+'_'+str(layer)+'.pt').to(device)\n",
        "\n",
        "                bias = torch.mm(output, eigvec)[:, 0]\n",
        "                bias_mat[layer] = np.array(bias.tolist())\n",
        "            self.bias_score_per_layer.append({\"sentence\":self.lines[i],\"tokens\":self.examples[i],\"mat\":bias_mat})\n",
        "        return self.bias_score_per_layer\n",
        "\n",
        "template = CSPTemplate()\n"
      ],
      "metadata": {
        "id": "cpq25epz5Sz_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./newresult/CSP_DR_scores.txt\", \"wb\") as handle:\n",
        "  pickle.dump(template.bias_score_per_layer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "T8c4Ivgv7ch3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ATTCAT calculation for CSP dataset"
      ],
      "metadata": {
        "id": "B3chMPH9OWJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_batch = masked_sentence\n",
        "CSP_map = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "\n",
        "\n",
        "for id in range(len(masked_sentence)):\n",
        "\n",
        "  encoding  = tokenizer.encode_plus(text_batch[id], add_special_tokens=True, max_length=128,return_tensors=\"pt\")\n",
        "  input_ids = encoding['input_ids'].to(device)\n",
        "  attention_mask = encoding['attention_mask'].to(device)\n",
        "  attention_mask[0][0] = 0\n",
        "  attention_mask[0][-1] = 0\n",
        "  tokens = tokenizer.convert_ids_to_tokens(input_ids.flatten())\n",
        "  result = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True,output_attentions=True)\n",
        "  hs = result[1]\n",
        "  loc = encoding['input_ids'].tolist()[0].index(103)\n",
        "  mask_hidden_state = result[0].squeeze(0)[loc]\n",
        "\n",
        "  softmax = torch.nn.Softmax(dim=0)\n",
        "  torch.set_grad_enabled(True)\n",
        "\n",
        "  probs = softmax(mask_hidden_state)\n",
        "\n",
        "  # 1 he 0 she\n",
        "  index = np.argmax(probs.tolist())#he_id #if mask_hidden_state[he_id].item()>mask_hidden_state[she_id].item() else she_id\n",
        "\n",
        "  # blk_id = layer id\n",
        "  kwargs = {\"alpha\": 1}\n",
        "\n",
        "  # turn the binary result[0] into real category (with max prob) tensor one_hot\n",
        "  one_hot = np.zeros((1, mask_hidden_state.size()[-1]), dtype=np.float32) # array([[0., 0.]], dtype=float32)\n",
        "  one_hot[0, index] = 1 # array([[1., 0.]], dtype=float32)\n",
        "  one_hot_vector = one_hot\n",
        "  one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
        "  one_hot = torch.sum(one_hot.to(device) * mask_hidden_state) #tensor(1.9705, device='cuda:0', grad_fn=<SumBackward0>)\n",
        "  for blk_id in range(nlayer):\n",
        "    hs[blk_id].retain_grad()\n",
        "\n",
        "  model.zero_grad()\n",
        "  one_hot.backward(retain_graph=True)\n",
        "\n",
        "\n",
        "  mask_id=1\n",
        "  AttCAT = [] # (12, 13) list of 12 layers, each layer with 1 CAT\n",
        "  raws = []\n",
        "  CAT_h = []\n",
        "  CAT=[]\n",
        "  for blk_id in range(nlayer):\n",
        "      hs_grads = hs[blk_id].grad\n",
        "      # # [batchsize, head, num_token, num_token].squeeze -- [head, num_token, num_token]\n",
        "      raw = result[2][blk_id].squeeze(0) # shape torch.Size([12, 13, 13])\n",
        "      avghead = raw.mean(dim=0)\n",
        "      att = avghead[mask_id] # torch.Size([13]) Q_mask_id\n",
        "      avgtoken = raw[:,mask_id,:].mean(dim=-1)#.mean(dim=-1)\n",
        "\n",
        "      # torch.Size([1, 13, 768])\n",
        "      # hidden states average pooling\n",
        "      cat = (hs_grads * hs[blk_id]).sum(dim=-1).squeeze(0)\n",
        "      CAT.append(cat.cpu().detach().numpy())\n",
        "      cat = cat * att # hardmard product\n",
        "\n",
        "      #avgtoken = avgtoken * cat\n",
        "\n",
        "      cat = cat.cpu().detach().numpy()\n",
        "      avgtoken = avgtoken.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "      AttCAT.append(cat) # torch.Size([13])\n",
        "      CAT_h.append(avgtoken)\n",
        "      raws.append(att.cpu().detach().numpy())\n",
        "\n",
        "  AttCAT = np.array(AttCAT)[:,1:-1]\n",
        "\n",
        "  raws = np.array(raws)[:,1:-1]\n",
        "\n",
        "  CAT_h = np.array(CAT_h) # 12*12\n",
        "  CAT = np.array(CAT)[:,1:-1]\n",
        "  CSP_map.append({\"AttCAT\":AttCAT\n",
        "                  ,\"raws\":raws\n",
        "                  ,\"CAT_h\":CAT_h\n",
        "                  ,\"CAT\":CAT\n",
        "                  ,\"lines\":text_batch[id]\n",
        "                  ,\"tokens\":tokens\n",
        "                  ,\"mask\":attention_mask.cpu().detach().numpy()})"
      ],
      "metadata": {
        "id": "vZCkFTsbOTjq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"./newresult/OCCTMP_mask_CSP.txt\", \"wb\") as handle:\n",
        "  pickle.dump(CSP_map, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "fIfSh_J1a1oY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class Template_CSP:\n",
        "    def __init__(self,path =\"./newresult/CSP_mask_lines.txt\"):\n",
        "        with open(path,\"rb\") as file:\n",
        "          self.lines = pickle.load(file)\n",
        "\n",
        "        encoding = tokenizer.batch_encode_plus(self.lines, add_special_tokens=True, max_length=128)\n",
        "        self.examples = encoding[\"input_ids\"]\n",
        "        self.attention_mask = encoding[\"attention_mask\"]\n",
        "        #self.get_bias_score_per_layer()\n",
        "\n",
        "\n",
        "    def get_bias_score_per_layer(self):\n",
        "        self.bias_score_per_layer = []\n",
        "        for i in range(len(self.examples)):\n",
        "            mask =torch.tensor(self.attention_mask[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            mask[0][0]=mask[0][-1] =0\n",
        "            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "            bias_mat = np.zeros((nlayer,len(self.examples[i])-2))\n",
        "            # (num_token, 768) @ (768,768)\n",
        "            for layer in range(nlayer):\n",
        "                # get embedding of each layer\n",
        "                #output = model(vec,attention_mask=mask)[1][layer+1][0][1:-1]\n",
        "                output = model(vec)[1][layer+1][0][1:-1]\n",
        "                eigvec = torch.load('./result/eigvecs_'+config+'_wiki_'+str(nsamples)+'_'+str(layer)+'.pt').to(device)\n",
        "\n",
        "                bias = torch.mm(output, eigvec)[:, 0]\n",
        "                bias_mat[layer] = np.array(bias.tolist())\n",
        "            self.bias_score_per_layer.append({\"sentence\":self.lines[i],\"tokens\":self.examples[i],\"mat\":bias_mat})\n",
        "        return self.bias_score_per_layer\n",
        "\n",
        "template = Template()\n"
      ],
      "metadata": {
        "id": "10A29H6J0jTo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c91dc4321b394f4d95ecda29b0394a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5093c59edce24ff788270b14fca0980d",
              "IPY_MODEL_f262b473bfdc46a99db7eed418efd951",
              "IPY_MODEL_27a1fe9f0bea444f8b66aa9f8c546a95"
            ],
            "layout": "IPY_MODEL_07a754db1429439aa2045afa47b53442"
          }
        },
        "5093c59edce24ff788270b14fca0980d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e58a6f428a84c59af4af9e395e08fd5",
            "placeholder": "​",
            "style": "IPY_MODEL_984708f5b5fe46389ef3dcf84ff2d728",
            "value": "config.json: 100%"
          }
        },
        "f262b473bfdc46a99db7eed418efd951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f04d6432db274836b9bd8cb274f5f6f2",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_391e93da1d164ea7a9bd6fa68056d0a8",
            "value": 570
          }
        },
        "27a1fe9f0bea444f8b66aa9f8c546a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a262832ada24a31b89503afb4cecf21",
            "placeholder": "​",
            "style": "IPY_MODEL_2416a47d596c4c87b142feb8b13b011c",
            "value": " 570/570 [00:00&lt;00:00, 15.7kB/s]"
          }
        },
        "07a754db1429439aa2045afa47b53442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e58a6f428a84c59af4af9e395e08fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "984708f5b5fe46389ef3dcf84ff2d728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f04d6432db274836b9bd8cb274f5f6f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "391e93da1d164ea7a9bd6fa68056d0a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a262832ada24a31b89503afb4cecf21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2416a47d596c4c87b142feb8b13b011c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8852df70a1e44795915522025ba23892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5cd1924a30d4d61b887989346a175bf",
              "IPY_MODEL_9bc8edac6b054082b1735f55de306319",
              "IPY_MODEL_dc16f7cb927b40b7afb3cde01a2d3995"
            ],
            "layout": "IPY_MODEL_3f94babc44ce4087bc9fddbebedcf17c"
          }
        },
        "e5cd1924a30d4d61b887989346a175bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4655b2acfa0846c988f410aad779244c",
            "placeholder": "​",
            "style": "IPY_MODEL_2191a38c63aa45c2823ac548b9f03f26",
            "value": "model.safetensors: 100%"
          }
        },
        "9bc8edac6b054082b1735f55de306319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d254e59251f4d43ac220b333a7002bb",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_944d0c0a57de49a68c6d1bbe42b416a5",
            "value": 440449768
          }
        },
        "dc16f7cb927b40b7afb3cde01a2d3995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eff1abe001524a598f30667490c81774",
            "placeholder": "​",
            "style": "IPY_MODEL_ee511efd47684244806e17a38add6c97",
            "value": " 440M/440M [00:01&lt;00:00, 235MB/s]"
          }
        },
        "3f94babc44ce4087bc9fddbebedcf17c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4655b2acfa0846c988f410aad779244c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2191a38c63aa45c2823ac548b9f03f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d254e59251f4d43ac220b333a7002bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "944d0c0a57de49a68c6d1bbe42b416a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eff1abe001524a598f30667490c81774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee511efd47684244806e17a38add6c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4329830733bb430697062ea3884e67ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f69efb327b1745f480cd22b8f455fc91",
              "IPY_MODEL_cea1a08d60114a5dbe1804262c44a781",
              "IPY_MODEL_e1400398d3c24e29856c53d52a1de974"
            ],
            "layout": "IPY_MODEL_a4a222d08ee3433e8260d65b9c03e59f"
          }
        },
        "f69efb327b1745f480cd22b8f455fc91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15b7d28f38ef4682bc6c5515ed234c31",
            "placeholder": "​",
            "style": "IPY_MODEL_0d6ed38204384154b69de59d7f1dc1d4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "cea1a08d60114a5dbe1804262c44a781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_828f2f9c7442447fa449d6b18c5424cd",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15b6e474703c47e0891ebdb0d643bb8e",
            "value": 28
          }
        },
        "e1400398d3c24e29856c53d52a1de974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e85d846df38d4be385e6882d28f774bc",
            "placeholder": "​",
            "style": "IPY_MODEL_383e1ecfe88642a7983822764ac25d28",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.82kB/s]"
          }
        },
        "a4a222d08ee3433e8260d65b9c03e59f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15b7d28f38ef4682bc6c5515ed234c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d6ed38204384154b69de59d7f1dc1d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "828f2f9c7442447fa449d6b18c5424cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15b6e474703c47e0891ebdb0d643bb8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e85d846df38d4be385e6882d28f774bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "383e1ecfe88642a7983822764ac25d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5485e05ad26d461d9b666ce5527ac067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a13367f35dc84f84a3d3285a88ce9ce1",
              "IPY_MODEL_c20d0f7bd6844413825adf9d55323f9b",
              "IPY_MODEL_813f14639baf4263a0c7ad33d3b9c6d0"
            ],
            "layout": "IPY_MODEL_deabb35d3d4b4939b6130641b3d0ce16"
          }
        },
        "a13367f35dc84f84a3d3285a88ce9ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15151a03869e479abcaf54f65e50028c",
            "placeholder": "​",
            "style": "IPY_MODEL_18ae677439dc41d8932167b6a249a917",
            "value": "vocab.txt: 100%"
          }
        },
        "c20d0f7bd6844413825adf9d55323f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e8de59926e2458b8f585aa3f3630366",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24bbd3af20a94bc28af3d6330e21fc25",
            "value": 231508
          }
        },
        "813f14639baf4263a0c7ad33d3b9c6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3cde637ecfc4f3baeb63737300d9866",
            "placeholder": "​",
            "style": "IPY_MODEL_2d04a8b05fc44858b83355025cb3f15a",
            "value": " 232k/232k [00:00&lt;00:00, 6.64MB/s]"
          }
        },
        "deabb35d3d4b4939b6130641b3d0ce16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15151a03869e479abcaf54f65e50028c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18ae677439dc41d8932167b6a249a917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e8de59926e2458b8f585aa3f3630366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24bbd3af20a94bc28af3d6330e21fc25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3cde637ecfc4f3baeb63737300d9866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d04a8b05fc44858b83355025cb3f15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2af3415d4055439a81056171366ccc19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_368ba8ef5f864e0c9bc9a2b79c4275aa",
              "IPY_MODEL_765a9ed9044d4a5398924a45e46ed0d6",
              "IPY_MODEL_d3fcbf04b57c4880a9046c5b9272248f"
            ],
            "layout": "IPY_MODEL_8aef96e1b08641698c2af201d237283d"
          }
        },
        "368ba8ef5f864e0c9bc9a2b79c4275aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f21c020ee9544b5bf81228e237d2b3d",
            "placeholder": "​",
            "style": "IPY_MODEL_86974ccdf4dd478c82e2a428554e72fa",
            "value": "tokenizer.json: 100%"
          }
        },
        "765a9ed9044d4a5398924a45e46ed0d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c720df2a03634c1a85961b7ff168a837",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa77eff8475f4c1bbc9404660e6aa4bb",
            "value": 466062
          }
        },
        "d3fcbf04b57c4880a9046c5b9272248f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c64aff0d7e5044a487da7df3e38fa89f",
            "placeholder": "​",
            "style": "IPY_MODEL_c3bf0b315304434bb7b52be6a9f35c3a",
            "value": " 466k/466k [00:00&lt;00:00, 7.03MB/s]"
          }
        },
        "8aef96e1b08641698c2af201d237283d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f21c020ee9544b5bf81228e237d2b3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86974ccdf4dd478c82e2a428554e72fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c720df2a03634c1a85961b7ff168a837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa77eff8475f4c1bbc9404660e6aa4bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c64aff0d7e5044a487da7df3e38fa89f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3bf0b315304434bb7b52be6a9f35c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}